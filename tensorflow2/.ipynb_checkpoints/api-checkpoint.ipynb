{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本笔记参考了下面的书籍、文献、博客或者官方说明：\n",
    "* TensorFlow2官方文档：https://tensorflow.google.cn/\n",
    "* 简单粗暴TensorFlow 2：https://github.com/snowkylin/tensorflow-handbook\n",
    "* TensorFlow 2.0 学习笔记：https://zhuanlan.zhihu.com/p/74441082\n",
    "\n",
    "未注明出处的代码示例，`大概`就是我自己编的，`大概`的意思就是也有极小的概率是忘记注明了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets  as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing as prep\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.TensorArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在部分网络结构，尤其是涉及到时间序列的结构中，我们可能需要将一系列张量以数组的方式依次存放起来，以供进一步处理。当然，在即时执行模式下，你可以直接使用一个 Python 列表（List）存放数组。不过，如果你需要基于计算图的特性（例如使用 @tf.function 加速模型运行或者使用 SavedModel 导出模型），就无法使用这种方式了。因此，TensorFlow 提供了 tf.TensorArray ，一种支持计算图特性的 TensorFlow 动态数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `arr = tf.TensorArray(dtype, size, dynamic_size=False) `：声明一个大小为 size ，类型为 dtype 的 TensorArray arr 。如果将 dynamic_size 参数设置为 True ，则该数组会自动增长空间。\n",
    "* `write(index, value)` ：将 value 写入数组的第 index 个位置；\n",
    "* `read(index)` ：读取数组的第 index 个值；\n",
    "* 请注意，由于需要支持计算图， tf.TensorArray 的 write() 方法是不可以忽略左值的！也就是说，在图执行模式下，必须按照以下的形式写入数组：\n",
    "`arr = arr.write(index, value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x14be1ebe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.TensorArray(dtype=tf.float32, size=3, infer_shape=False, clear_after_read=False)\n",
    "a = tf.random.normal([3,2,2])\n",
    "x.unstack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.866212  , -2.7629073 ],\n",
       "       [ 0.07647694,  0.12429674]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[ 0.20986849,  1.0732858 ],\n",
       "        [ 0.16812925, -0.8615574 ]],\n",
       "\n",
       "       [[ 0.5049179 ,  0.75962025],\n",
       "        [ 0.34235328,  2.0449383 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gather([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.5049179 , 0.75962025],\n",
       "       [0.34235328, 2.0449383 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.scatter([2,1,0], a)  # infer_shape=True时不能用\n",
    "y.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x14be1ebe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([5,6])\n",
    "x.split(a, [1,2,2]) # 长度分别是1，2，2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[ 1.1342567 ,  1.2032253 , -0.5454625 ,  0.6039174 , -0.53120303,\n",
       "        -0.81809044]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[ 1.1342567 ,  1.2032253 , -0.5454625 ,  0.6039174 , -0.53120303,\n",
       "        -0.81809044]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[-0.37452495,  1.5670388 ,  0.14918514, -0.13703519, -0.81656194,\n",
       "         0.03038387],\n",
       "       [-1.3384736 ,  0.6575544 , -0.9972656 ,  0.11442024,  0.08054624,\n",
       "         0.03166075]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.TensorArray(tf.float32, 3, dynamic_size=True, clear_after_read=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x14be477b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unstack(tf.random.normal([4, 2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.7052294 ,  1.0569074 , -0.20574473],\n",
       "       [ 1.0249538 , -1.5954558 , -0.6838625 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.8342725 , -0.18422723, -0.35455483],\n",
       "       [ 0.19807559, -1.262542  ,  0.38357162]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.read(1)  # 由于clear_after_read=True，第二次read(1)时会异常"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，因为 SavedModel 基于计算图，所以对于使用继承 tf.keras.Model 类建立的 Keras 模型，其需要导出到 SavedModel 格式的方法（比如 call ）都需要使用 @tf.function 修饰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "使用`tf.function`一章中的`MyModule`类的实例`m`展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name, units=10):\n",
    "        super(MyModule, self).__init__(name=name)\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.units = units\n",
    "        self.built = False  # tf.keras.layers.Layer会设置此属性，并且子类会继承，用于指示是否建立权重\n",
    "    @tf.Module.with_name_scope\n",
    "    def build(self, input_shape):\n",
    "        if self.w is None:\n",
    "            self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]))\n",
    "        if self.b is None:\n",
    "            self.b = tf.Variable(tf.random.normal([self.units, ]))\n",
    "        self.built = True  # 设置为True\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.w) + self.b\n",
    "    @tf.function\n",
    "    def __call__(self, input):\n",
    "        if not self.built:  # 第一次调用时built=False，调用build方法，建立权重\n",
    "          self.build(input.shape)\n",
    "        return self.call(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyModule('testModule')\n",
    "input = tf.random.normal([5,3])\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/modelDir/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x14bfae860>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.save(m, \"data/modelDir\")\n",
    "tf.saved_model.load(\"data/modelDir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 参数可以是log后的概率值，这个写法会以0.1，0.3，0.6的概率从多项式分布中随机抽取\n",
    "x = tf.random.categorical(tf.math.log([[0.1,0.3,0.6]]), 1000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=111>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.cast(x==0, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 概率分别是[1., 2., 6.]/tf.reduce_sum([1., 2. 6.])\n",
    "x = tf.random.categorical(tf.math.log([[6., 1. , 1.], [1,1,10]]), 10) \n",
    "# 换一种说法就是，按照参数tf.exp变换后所占的比例作为随机抽样的概率，相当于对参数做了softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=int64, numpy=\n",
       "array([[0, 0, 0, 0, 2, 0, 1, 0, 1, 0],\n",
       "       [2, 2, 0, 2, 2, 1, 2, 2, 2, 2]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint只保存模型的参数，不保存模型的计算过程，因此一般用于在具有模型源码的时候恢复之前训练好的模型参数。\n",
    "```python3\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.save(save_path_with_prefix)\n",
    "```\n",
    "* 这里tf.train.Checkpoint接受的参数比较特殊，是一个\\*\\*kwargs。具体而言，是一系列键值对，键名可以随便起，值为需要保存的对象。\n",
    "* `save_path_with_prefix`是保存文件的目录+前缀。例如在`checkpoint.save(\"./save/model.ckpt\")`，在save目录下会建立三个文件：`checkpoint, model.ckpt-1.index, model.ckpt-1.data-00000-of-00001`，这些文件记录了变量信息。`checkpoint.save`可以运行多次，每次运行都会得到一个`.index`文件和`.data`文件，序号一次累加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续训练模型可以用一下方式实现：\n",
    "```\n",
    "checkpoint = tf.train.Checkpoint(myAwesomeModel=model, myAwesomeOptimizer=optimizer)\n",
    "checkpoint.save(save_path_with_prefix)\n",
    "model_to_be_restored = MyModel() \n",
    "checkpoint = tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)\n",
    "checkpoint.restore(save_path_with_prefix_and_index)\n",
    "```\n",
    "* `save_path_with_prefix_and_index`是之前保存到文件的目录+前缀+编号。例如，调用`checkpoint.restore(\"./save/model.ckpt-1\")`，序号为1的文件来恢复模型。\n",
    "\n",
    "```\n",
    "tf.train.latest_checkpoint(save_path)\n",
    "```\n",
    "* 返回最近一次的checkpoint的文件名，比如返回`./save/model.ckpt-10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ckpt.save.test-1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: \"aaaa\"\n",
       "value: \"cccc\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_1 = tf.constant('aaaa')\n",
    "#x0 = tf.train.Feature(bytes_list=tf.train.BytesList(value=[value])) \n",
    "# BytesList won't unpack a string from an EagerTensor.\n",
    "if isinstance(value_1, type(tf.constant(0))):\n",
    "    value_1 = value_1.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "a = tf.train.BytesList(value=[value_1, b'cccc'])  # 只接受bytes对象\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes_list {\n",
       "  value: \"aaaa\"\n",
       "  value: \"cccc\"\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(['aaaa', 'cccc'])\n",
    "x = x.numpy() \n",
    "x0 = tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'aaaa', b'cccc']))\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_2 = tf.constant([4., 5.])\n",
    "x1 = tf.train.Feature(float_list=tf.train.FloatList(value=value_2))\n",
    "value_3 = tf.constant([2, 3])\n",
    "x2 = tf.train.Feature(int64_list=tf.train.Int64List(value=value_3))\n",
    "feature = {'x1':x1, 'x2':x2, 'x0':x0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  key: \"x0\"\n",
       "  value {\n",
       "    bytes_list {\n",
       "      value: \"aaaa\"\n",
       "      value: \"cccc\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"x1\"\n",
       "  value {\n",
       "    float_list {\n",
       "      value: 4.0\n",
       "      value: 5.0\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"x2\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 2\n",
       "      value: 3\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Features(feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"x0\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"aaaa\"\n",
       "        value: \"cccc\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"x1\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 4.0\n",
       "        value: 5.0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"x2\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 2\n",
       "        value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "如果深度学习模型的权重初始化得太小，那信号将在每层间传递时逐渐缩小而难以产生作用；如果权重初始化的太大，那信号将在每层间传递时逐渐放大并导致发散和失效。  \n",
    "Xavier初始化器让初始化权重满足均值为0，方差为$\\frac{2}{N_{in}+N_{out}}$均匀分布或者高斯分布；\n",
    "\n",
    "* `tf.initializers.glorot_normal()(shape=[20,30])`：创建 $N_{in}=20,N_{out}=30$ 服从正态分布的的初始化权重；\n",
    "* `tf.initializers.glorot_uniform()(shape=[20,30]`：与上面相同，只是服从的是均匀分布。\n",
    "\n",
    "也可以通过下面的api间接实现：  \n",
    "* `tf.random_normal_initializer(mean=0.0,stddev=0.05)(shape=[])`\n",
    "* `tf.random_uniform_initializer(minval=-0.05, maxval=0.05)(shape=[])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "matrix_band_part(input, num_lower, num_upper)\n",
    "```\n",
    "* num_lower: 下三角要保留的对角线数，-1表示全保留；num_upper类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.529435  ,  0.8286487 ,  1.837228  ,  0.09473267],\n",
       "       [ 0.36858612,  1.0950916 ,  0.62635964,  1.1934665 ],\n",
       "       [-0.7357971 ,  0.18043841, -0.19846489, -0.9738333 ],\n",
       "       [-1.5683837 ,  2.8496115 ,  0.01234788, -0.76184636]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.529435  ,  0.8286487 ,  1.837228  ,  0.09473267],\n",
       "       [ 0.        ,  1.0950916 ,  0.62635964,  1.1934665 ],\n",
       "       [ 0.        ,  0.        , -0.19846489, -0.9738333 ],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.76184636]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(x, 0, -1)  # 变成下三角矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.argmax_v2(input, axis=None, output_type=tf.int64, name=None)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_std # 标准差\n",
    "tf.math.reduce_variance # 方差\n",
    "tf.math.reduce_all\n",
    "tf.math.reduce_any\n",
    "tf.math.reduce_logsumexp # 相当于 tf.math.log(tf.reduce_sum(tf.exp(x)))\n",
    "tf.math.argmin\n",
    "tf.math.argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`tf.matmul(a, b)`  # 将最后两个维度用与矩阵乘法，前面的维度必须完全相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "在tf.GradientTape上下文中执行的所有操作记录下来，用于计算梯度。默认情况下，tf.GradientTape持有的资源会在调用GradientTape.gradient()方法后立即释放。要在同一计算中计算多个梯度，需要创建一个持久梯度带，这允许多次调用gradient()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=108.0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "  t.watch(x)  # 由于x是常数，所以要调用调用watch方法，如果是Variable则不需要这一行\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "dz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
    "dy_dx = t.gradient(y, x)  # 6.0\n",
    "del t  # Drop the reference to the tape\n",
    "dz_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "在上下文中的梯度计算也会被记录下来，因此可以实现高阶梯度计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * x * x\n",
    "    dy_dx = t2.gradient(y,x)\n",
    "d2y_dx2 = t.gradient(dy_dx, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert dy_dx.numpy() == 3.0\n",
    "assert d2y_dx2.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    x = x * x * 8.\n",
    "    y = x * x\n",
    "dydx = tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=144.0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dydx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
    "tf.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='auto')\n",
    "```\n",
    "* 其中y_true是稀疏矩阵，直接的label，而不是one-hot向量\n",
    "* from_logits=False时，y_pred是tf.nn.softmax输出结果，也就是每一个元素都是概率，每一行之和为1\n",
    "* from_logits=True时，y_pred是上一层的输出结果，也就是说softmax(y_pred)运算在此函数内执行\n",
    "* reduction='auto', 'sum_over_batch_size', 'sum'\n",
    "\n",
    "\n",
    "```\n",
    "tf.losses.categorical_crossentropy\n",
    "tf.lossed.CategoricalCrossentropy\n",
    "```\n",
    "* y_true是one-hot向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "两分类的交叉熵计算，可以看到下面三种计算方式结果一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.94, 0.01], [0.1, 0.8, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.06187541, 2.3025851 ], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- tf.reduce_sum(tf.multiply(tf.cast(y_true, tf.float32), tf.math.log(y_pred)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.06187541, 2.3025851 ], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.06187541, 2.3025851 ], dtype=float32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losser = tf.losses.CategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "losser(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.27290332>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.binary_crossentropy([1,0,1], [0.9,0.3,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.27290332>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.losses.binary_crossentropy([[1],[0],[1]], [[0.9],[0.3],[0.7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.27290347>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.multiply(tf.subtract(1.,[1,0,1.]), tf.math.log(tf.subtract(1.,[0.9,0.3,0.7])))\n",
    "b = tf.multiply([1,0,1.], tf.math.log([0.9,0.3,0.7]))\n",
    "-tf.reduce_mean(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "tf.metrics.categorical_accuracy(y_true, y_pred)\n",
    "* y_true是one-hot向量；y_pred是softmax输出\n",
    "\n",
    "tf.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "* y_true 是稀疏Tensor，y_pred是softmax输出的概率， 或者是logits也可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1.], [1], [0], [0]])\n",
    "b = tf.constant([[0.98], [1], [0], [0.55]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.BinaryAccuracy(threshold=0.5)(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tf.metrics.BinaryAccuracy(threshold=0.5)\n",
    "m(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.75>,\n",
       " <tf.Variable 'total:0' shape=() dtype=float32, numpy=3.0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result(), m.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.update_state([[1], [1], [0], [0]], [[0.98], [1], [0], [0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.75>,\n",
       " <tf.Variable 'total:0' shape=() dtype=float32, numpy=6.0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result(), m.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1., 1, 0, 0])\n",
    "b = tf.constant([0.98, 1, 0, 0.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.binary_accuracy(a, tf.where(b>0.5, 1., 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.binary_accuracy(a, b, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "optimizer.apply_gradient(zip(grads, model.trainable_variables))\n",
    "# .apply_gradient(grads_and_vars)\n",
    "# grads_and_vars: List of (gradient, variable) pairs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.gen_math_ops.tanh(x, name=None)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.sigmoid(x, name=None)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([6,3])\n",
    "b = tf.constant([2,1,1,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-1.7133043 ,  0.3444689 ,  0.5035624 ],\n",
       "       [ 0.28734338, -0.6957891 , -0.7670209 ],\n",
       "       [-1.2277938 , -1.5605494 , -0.09386743],\n",
       "       [ 0.6773767 , -0.6124227 , -1.237662  ],\n",
       "       [ 0.07477915,  0.94955546, -0.97859645],\n",
       "       [ 1.6891416 ,  1.896936  , -0.43835676]], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[ 0.5035624 ,  0.3444689 ],\n",
       "       [ 0.28734338, -0.6957891 ],\n",
       "       [-0.09386743, -1.2277938 ],\n",
       "       [ 0.6773767 , -0.6124227 ],\n",
       "       [ 0.94955546,  0.07477915],\n",
       "       [ 1.896936  ,  1.6891416 ]], dtype=float32)>, indices=<tf.Tensor: shape=(6, 2), dtype=int32, numpy=\n",
       "array([[2, 1],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=int32)>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.top_k(a,  2) # 最后一个轴中最大的前两个值以及它们的下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([2, 1, 1, 0, 0, 1], dtype=int32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=bool, numpy=array([ True,  True, False,  True,  True,  True])>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.in_top_k(b, a,  2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "tf.nn.moments(x, axes, keep_dims=False)\n",
    "# 若axes=[0,1,2]，则沿着[0,1,2]轴计算mean和variance\n",
    "# keep_dims 返回的结果是否保持原来的维度\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.random.normal([128, 32, 32, 64])\n",
    "m, v = tf.nn.moments(x, [0,1,2], keepdims=True)\n",
    "assert m.shape == [1,1,1,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 相当于\n",
    "m2 = tf.reduce_mean(x, axis=[0,1,2], keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_all(m == m2).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.batch_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```pthon\n",
    "tf.nn.batch_normalization(x, mean, variance, offset, scale, variance_epsilion)\n",
    "```\n",
    "* mean, variance可以是`tf.nn.moments`的输出结果\n",
    "* variance_epsilon一个接近0的值，防止0出现\n",
    "* 计算公式：\n",
    "```\n",
    "tmp = (x-mean)/tf.sqrt(variance + variance_epsilon)\n",
    "return tmp * scale + offset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.batch_normalization(x, m, v, 0, 1, 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.keras.layers.BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')\n",
    "```\n",
    "* axis：要标准化的特征轴\n",
    "* momentum：移动平均系数，一般公式中的 $\\alpha$ 为1-momentum\n",
    "* epsilon：同上面的variance_epsilon\n",
    "* scale：是否乘上scale\n",
    "* center：是否加上offset\n",
    "* gamma：同上面scale\n",
    "* beta：同上面offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "设当前层norm的状态为：移动平均值$\\mu$，标准差$\\sigma$；当前mini-batch样本的均值和标准差分别为：$\\mu_i,\\sigma_i$；  系数为$\\alpha$，也就是1 - norm.momentum；则\n",
    "$$\n",
    "\\mu = (1-\\alpha)\\mu + \\alpha \\mu_i \\\\\n",
    "\\sigma = (1-\\alpha)\\sigma + \\alpha\\sigma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization_1/moving_mean:0' shape=(5,) dtype=float32, numpy=\n",
       "array([-0.00110975,  0.00036719,  0.0031628 , -0.00068342, -0.00579923],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.random.normal([3, 4, 5])\n",
    "norm = layers.BatchNormalization()\n",
    "norm(tmp, training=True)\n",
    "norm.moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'batch_normalization_1/gamma:0' shape=(5,) dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/beta:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'batch_normalization_1/gamma:0' shape=(5,) dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/beta:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(5,) dtype=float32, numpy=\n",
       " array([-0.00110975,  0.00036719,  0.0031628 , -0.00068342, -0.00579923],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(5,) dtype=float32, numpy=\n",
       " array([1.0060341 , 0.99633485, 1.0017756 , 0.9977652 , 0.99740314],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### 计算过程\n",
    "参考这篇文献: [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/pdf/1702.03275.pdf)，其计算过程大概如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([6,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-0.91982466,  0.22108793,  1.372667  ],\n",
       "       [-0.41213787,  1.5481071 , -0.61506   ],\n",
       "       [-0.16976114, -1.3530649 , -0.65074354],\n",
       "       [-2.095482  , -0.21522683,  0.11636626],\n",
       "       [ 0.8393733 , -1.371746  , -0.4672847 ],\n",
       "       [ 0.2859292 ,  0.6168625 , -0.854694  ]], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.41198388, -0.09233003, -0.18312484], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.86728626, 1.0889467 , 0.57452846], dtype=float32)>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.moments(a, axes=0) # 计算均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-5.44999540e-01,  3.00207287e-01,  2.05077505e+00],\n",
       "       [-1.65253878e-04,  1.57129216e+00, -5.69357634e-01],\n",
       "       [ 2.59946227e-01, -1.20759451e+00, -6.16394043e-01],\n",
       "       [-1.80667984e+00, -1.17716655e-01,  3.94775778e-01],\n",
       "       [ 1.34291911e+00, -1.22548819e+00, -3.74566823e-01],\n",
       "       [ 7.48979449e-01,  6.79299772e-01, -8.85232449e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = layers.BatchNormalization()\n",
    "norm(a, training=True)  #设置权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization_2/moving_mean:0' shape=(3,) dtype=float32, numpy=array([-0.00411984, -0.0009233 , -0.00183125], dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.moving_mean # 初始化值为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization_2/moving_variance:0' shape=(3,) dtype=float32, numpy=array([0.99867284, 1.0008894 , 0.9957453 ], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.moving_variance # 初始化值为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization_2/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization_2/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "参数的更新计算方式与下面的计算方式相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.00411984, -0.0009233 , -0.00183125], dtype=float32)>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum * 0 + tf.nn.moments(a, axes=0)[0] * (1-norm.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.99867284, 1.0008894 , 0.9957453 ], dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum * 1. + tf.nn.moments(a, axes=0)[1] * (1-norm.momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### `training=False`时计算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-0.9158547 ,  0.22180179,  1.3767406 ],\n",
       "       [-0.4080848 ,  1.5475692 , -0.61422914],\n",
       "       [-0.16566841, -1.3508661 , -0.64997095],\n",
       "       [-2.0917046 , -0.21410136,  0.11839034],\n",
       "       [ 0.8436312 , -1.3695295 , -0.46621278],\n",
       "       [ 0.2900965 ,  0.617203  , -0.8542541 ]], dtype=float32)>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-0.9158547 ,  0.2218018 ,  1.3767406 ],\n",
       "       [-0.40808478,  1.5475692 , -0.61422914],\n",
       "       [-0.1656684 , -1.3508661 , -0.6499709 ],\n",
       "       [-2.0917044 , -0.21410136,  0.11839033],\n",
       "       [ 0.84363115, -1.3695295 , -0.46621278],\n",
       "       [ 0.29009652,  0.61720294, -0.85425407]], dtype=float32)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#等同于下面的计算：\n",
    "(a-norm.moving_mean)/(norm.moving_variance+norm.epsilon)**0.5 * norm.gamma+norm.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### `training=True`时的计算方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "我猜测应该是按照下面的方式计算的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-5.44999480e-01,  3.00207317e-01,  2.05077529e+00],\n",
       "       [-1.65255959e-04,  1.57129216e+00, -5.69357574e-01],\n",
       "       [ 2.59946197e-01, -1.20759451e+00, -6.16394103e-01],\n",
       "       [-1.80667984e+00, -1.17716655e-01,  3.94775808e-01],\n",
       "       [ 1.34291911e+00, -1.22548819e+00, -3.74566853e-01],\n",
       "       [ 7.48979390e-01,  6.79299831e-01, -8.85232449e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a-tf.nn.moments(a, axes=0)[0])/(tf.nn.moments(a, axes=0)[1] + norm.epsilon)**0.5 * norm.gamma + norm.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[-5.44999540e-01,  3.00207287e-01,  2.05077505e+00],\n",
       "       [-1.65253878e-04,  1.57129216e+00, -5.69357634e-01],\n",
       "       [ 2.59946227e-01, -1.20759451e+00, -6.16394043e-01],\n",
       "       [-1.80667984e+00, -1.17716655e-01,  3.94775778e-01],\n",
       "       [ 1.34291911e+00, -1.22548819e+00, -3.74566823e-01],\n",
       "       [ 7.48979449e-01,  6.79299772e-01, -8.85232449e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = keras.layers.BatchNormalization(axis=[-2, -1])\n",
    "x = tf.random.normal([6,5,4,3])\n",
    "_ = norm(x, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'batch_normalization_9/gamma:0' shape=(1, 1, 4, 3) dtype=float32, numpy=\n",
       " array([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/beta:0' shape=(1, 1, 4, 3) dtype=float32, numpy=\n",
       " array([[[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/moving_mean:0' shape=(1, 1, 4, 3) dtype=float32, numpy=\n",
       " array([[[[-0.00221661, -0.00137228,  0.00279443],\n",
       "          [ 0.00341048, -0.00194845, -0.00075563],\n",
       "          [-0.00315018, -0.00273164, -0.00047328],\n",
       "          [-0.00027766, -0.00072617,  0.00263126]]]], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/moving_variance:0' shape=(1, 1, 4, 3) dtype=float32, numpy=\n",
       " array([[[[1.0037653 , 1.0002662 , 0.9988896 ],\n",
       "          [1.0039077 , 1.0024092 , 0.99825966],\n",
       "          [0.9961058 , 0.99810433, 1.0003287 ],\n",
       "          [0.999886  , 0.99815106, 0.99864   ]]]], dtype=float32)>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.3310644e-04, 9.9297631e-01, 6.6906218e-03],\n",
       "       [4.5094042e-05, 6.6925492e-03, 9.9326235e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[ 3., 11.,  6.],[ 6., 11., 16.]])\n",
    "tf.nn.softmax(x)\n",
    "# 相当于：tf.exp(x)/tf.expand_dims(tf.reduce_sum(tf.exp(x), axis=1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "```\n",
    "* 计算交叉熵，输入是softmax的输入，也就是说softmax的计算是在此函数的内部完成的；\n",
    "* 注意返回是的一个batch的所有样本组成的向量，要求批次总的交叉熵，还要使用tf.reduce_sum；\n",
    "* logits:神经网络最后一层的输出，维度是`[batch_size, num_classes]`，如果是单个样本那维度就是num_classes；\n",
    "* labels:样本的实际标签，维度与上面相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.3310644e-04, 9.9297631e-01, 6.6906218e-03],\n",
       "       [4.5094042e-05, 6.6925492e-03, 9.9326235e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[ 3., 11.,  6.],[ 6., 11., 16.]])\n",
    "tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.0070485 , 0.00676046], dtype=float32)>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sparse_softmax_cross_entropy_with_logits([1,2], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.0070485 , 0.00676046], dtype=float32)>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits(tf.one_hot([1,2], depth=3), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00704847, 0.00676045], dtype=float32)>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- tf.reduce_sum(tf.math.log(tf.nn.softmax(x)) * tf.one_hot([1,2], depth=3), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.nn.conv2d(input, filters, strides, padding, data_format='NHWC', dilations=None, name=None)\n",
    "```\n",
    "* 第一个参数input，要求shape必须满足`[batch, in_height, in_weight, in_channels]`，具体的含义是`[训练时一个batch的图片数量，图片高度，图片宽度，图像通道数]`\n",
    "* 第二个参数filters是卷积核，要求shape必须满足`[filter_height,filter_width,in_channels,out_channels]`，具体的含义是`[卷积核的高度，卷积核的宽度，图像的通道数，卷积核的个数]`\n",
    "* 第三个参数strides，卷积时在图像每一维的步长，这是一个一维张量，对于图片来说，`strides=[1, x, y, 1]，strides[0]==strides[3]==1`；\n",
    "* 第四个参数padding，string类型的量，只能是“SAME”，“VALID”其中之一，这个值决定了不同的卷积方式， padding=\"SAME\"表示有padding，前后补0，保证行列数不变，padding=\"VALID\"表示不加padding；\n",
    "* 第五个参数，use_cudnn_on_gpu: bool类型，是否使用cudnn加速；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 7, 7, 8])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = layers.Conv2D(filters=8, kernel_size=[4,4])\n",
    "x = tf.random.normal([6, 10, 10, 3])\n",
    "t(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 3, 8])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.variables[0].shape # 卷积核权重的个数，每个卷积核大小为[height,width,in_channels]，卷积核的个数为out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.variables[1].shape # 卷积运算的bias个数，每个卷积核对应一个bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = tf.io.read_file('data/thelight.jpg')\n",
    "arr_img = tf.image.decode_jpeg(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.image.adjust_brightness(arr_img, 0.2)  # 计算方式：arr_img - 0.2 * 255, 调整亮度，负数的话是减小亮度\n",
    "tf.image.adjust_contrast(arr_img, 0.2) # 调整对比度，相当于a=np.mean(arr_img.numpy(), axis=(0,1));tf.cast((0.2 * (arr_img.numpy() - a) + a), 'uint8')\n",
    "tf.image.adjust_gamma(arr_img, gamma=0.2, gain=1）# 大概相当于tf.cast(255 * (arr_img/255)**0.2, 'uint8')\n",
    "tf.image.random_crop(star, [1000,1000, 3])  # 随机切去[1000,1000]大小的图片，支持批量操作\n",
    "tf.image.random_crop(tf.stack([star, star], 0), [2, 1000, 1000, 3])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.image.flip_left_right(img)  # 左右镜像对称\n",
    "tf.image.rgb_to_grayscale  # 转换为灰度图\n",
    "tf.image.rgb_to_hsv(image)  # image需在[0,1]范围内\n",
    "tf.image.adjust_saturation(image, 3)  # 将image转换为hsv格式后，再将饱和度通道的值乘以3，再转换为rgb格式\n",
    "tf.image.rot90  # 旋转90度\n",
    "tf.image.central_crop(image, central_fraction=0.5) # 剪切，只留下中间50%\n",
    "tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "\n",
       "   ca    thal  target  \n",
       "0   0   fixed       0  \n",
       "1   3  normal       1  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
    "dataframe = pd.read_csv(URL)\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': array([63, 67, 67, 37, 41, 56, 62, 57], dtype=int32),\n",
       " 'sex': array([1, 1, 1, 1, 0, 1, 0, 0], dtype=int32),\n",
       " 'cp': array([1, 4, 4, 3, 2, 2, 4, 4], dtype=int32),\n",
       " 'trestbps': array([145, 160, 120, 130, 130, 120, 140, 120], dtype=int32),\n",
       " 'chol': array([233, 286, 229, 250, 204, 236, 268, 354], dtype=int32),\n",
       " 'fbs': array([1, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'restecg': array([2, 2, 2, 0, 2, 0, 2, 0], dtype=int32),\n",
       " 'thalach': array([150, 108, 129, 187, 172, 178, 160, 163], dtype=int32),\n",
       " 'exang': array([0, 1, 1, 0, 0, 0, 0, 1], dtype=int32),\n",
       " 'oldpeak': array([2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6]),\n",
       " 'slope': array([3, 2, 2, 3, 1, 1, 3, 1], dtype=int32),\n",
       " 'ca': array([0, 3, 2, 0, 0, 0, 2, 0], dtype=int32),\n",
       " 'thal': array([b'fixed', b'normal', b'reversible', b'normal', b'normal',\n",
       "        b'normal', b'normal', b'normal'], dtype=object)}"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataframe.pop('target')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "dataset = dataset.batch(8)\n",
    "one_batch = next(dataset.as_numpy_iterator())[0]\n",
    "one_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.numeric_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "one_age = tf.feature_column.numeric_column('age')\n",
    "feature_layer = layers.DenseFeatures([one_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [2.]], dtype=float32)>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(dict(age=[1,2], ppp=[3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[63.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [37.],\n",
       "       [41.],\n",
       "       [56.],\n",
       "       [62.],\n",
       "       [57.]], dtype=float32)>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.bucketized_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buck_age = tf.feature_column.bucketized_column(one_age, boundaries=[37, 40, 65, 67, 70]) # 输入是numeric_column\n",
    "feature_layer = layers.DenseFeatures(buck_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch) # 第一个区间是开区间，后面的是左闭右开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.categorical_column_with_vocabulary_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.indicator_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.embedding_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DenseFeatures only accepts dense tensors, to inspect a categorical column you need to transform that to a indicator column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thal = tf.feature_column.categorical_column_with_vocabulary_list('thal',  ['fixed', 'normal', 'reversible'])\n",
    "thal_one_hot = tf.feature_column.indicator_column(thal)\n",
    "feature_layer = layers.DenseFeatures(thal_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thal_embedding = tf.feature_column.embedding_column(thal, 3)\n",
    "feature_layer = layers.DenseFeatures(thal_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[-0.5390322 , -0.44834587, -0.07046258],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [-0.5288149 ,  0.34261864,  0.02457438],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ]], dtype=float32)>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = layers.DenseFeatures([one_age, buck_age, thal_one_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 10), dtype=float32, numpy=\n",
       "array([[63.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [67.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.],\n",
       "       [67.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
       "       [37.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [41.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [56.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [62.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [57.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features(one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow_hub Reusable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name, units=5):\n",
    "        super(MyModule, self).__init__(name=name)\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.units = units\n",
    "        self.built = False  # tf.keras.layers.Layer会设置此属性，并且子类会继承，用于指示是否建立权重\n",
    "    @tf.Module.with_name_scope\n",
    "    def build(self, input_shape):\n",
    "        if self.w is None:\n",
    "            self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]))\n",
    "        if self.b is None:\n",
    "            self.b = tf.Variable(tf.random.normal([self.units, ]))\n",
    "        self.built = True  # 设置为True\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.w) + self.b\n",
    "    @tf.function\n",
    "    def __call__(self, input):\n",
    "        if not self.built:  # 第一次调用时built=False，调用build方法，建立权重\n",
    "          self.build(input.shape)\n",
    "        return self.call(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubModule(tf.train.Checkpoint):\n",
    "    def __init__(self, model):\n",
    "        super(HubModule, self).__init__()\n",
    "        self.model = model\n",
    "        self.variables = model.variables\n",
    "        self.trainable_variables = model.trainable_variables\n",
    "    @tf.function(input_signature=[tf.TensorSpec([2, 3], dtype=tf.float32)])\n",
    "    def __call__(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyModule('nnn')\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/hub/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/hub/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(HubModule(m), 'model/hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这三种写法都没有问题\n",
    "#m2 = tf.saved_model.load('model/hub')\n",
    "# m2 = hub.load('model/hub') \n",
    "\n",
    "m2 = hub.KerasLayer('model/hub', trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = copy.deepcopy(m2.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'nnn/Variable:0' shape=(5,) dtype=float32, numpy=\n",
       " array([ 0.0128301 , -0.38711149, -1.0720037 ,  0.5841067 , -1.4495848 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'nnn/Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
       " array([[-0.9564233 ,  0.51733613, -1.8141801 ,  0.15252951, -0.9327845 ],\n",
       "        [-1.669865  ,  0.8874694 , -0.14137633,  0.68015844,  0.8777286 ],\n",
       "        [-0.6864597 ,  0.61776245, -1.0815104 ,  0.9587199 ,  0.7806263 ]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(0.5)\n",
    "with tf.GradientTape() as tape:\n",
    "  y = m2(x)\n",
    "  loss = tf.math.reduce_euclidean_norm(y-1)\n",
    "grad = tape.gradient(loss, m2.trainable_variables)\n",
    "optimizer.apply_gradients(grads_and_vars= zip(grad, m2.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'nnn/Variable:0' shape=(5,) dtype=float32, numpy=\n",
       " array([ 0.11147295, -0.09057796, -0.81769305,  0.7207276 , -0.9929245 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'nnn/Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
       " array([[-0.9823717 ,  0.47344562, -1.8047373 ,  0.11407161, -0.9993112 ],\n",
       "        [-1.5960433 ,  0.8954189 , -0.42987692,  0.79820263,  0.8832942 ],\n",
       "        [-0.83529687,  0.49052802, -0.7487032 ,  0.72893465,  0.59467673]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([ 0.11147295, -0.09057796, -0.81769305,  0.7207276 , -0.9929245 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       " array([[-0.9823717 ,  0.47344562, -1.8047373 ,  0.11407161, -0.9993112 ],\n",
       "        [-1.5960433 ,  0.8954189 , -0.42987692,  0.79820263,  0.8832942 ],\n",
       "        [-0.83529687,  0.49052802, -0.7487032 ,  0.72893465,  0.59467673]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a[0] - grad[0]*0.5, a[1] - grad[1]*0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
