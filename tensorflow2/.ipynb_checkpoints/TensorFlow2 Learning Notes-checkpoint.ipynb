{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2学习笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本笔记参考了下面的书籍、文献、博客或者官方说明：\n",
    "* TensorFlow2官方文档：https://tensorflow.google.cn/\n",
    "* 简单粗暴TensorFlow 2：https://github.com/snowkylin/tensorflow-handbook\n",
    "* TensorFlow 2.0 学习笔记：https://zhuanlan.zhihu.com/p/74441082\n",
    "\n",
    "未注明出处的代码示例，`大概`就是我自己编的，`大概`的意思就是也有极小的概率是忘记注明了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets  as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing as prep\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.training.tracking.base import Trackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1493a9588>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Trackable()\n",
    "y = Trackable()\n",
    "x._track_trackable(y, 'ccc') # x引用y，并且叫该引用命名为'ccc'，或者说x依赖y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc') is y  # 返回名称为'ccc'的引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1493a9588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1493a9588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1493a9588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到删除y之后，不影响x对其引用。因此只要根节点x没有被回收，那么x所依赖的对象就不会被回收。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoTrackable\n",
    "AutoTrackabke类继承Trackable类，通过`__setattr__`和`__getattr__`属性拦截访问和设置新属性（访问和建立依赖关系）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.training.tracking.tracking import AutoTrackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AutoTrackable()\n",
    "y = AutoTrackable()\n",
    "x.ccc = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc') is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.vvv = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrackableReference(name='ccc', ref=<tensorflow.python.training.tracking.tracking.AutoTrackable object at 0x1493c15c0>),\n",
       " TrackableReference(name='vvv', ref=<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._unconditional_checkpoint_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可以被保存的对象\n",
    "**tf.Variable和MutableHashTable**  \n",
    "tf.Variable类和MutableHashTable类是可以被保存的对象(用于tf.train.Checkpoint)，这两个类继承自Trackable类，并且覆盖了`_gather_saveables_for_checkpoint`方法，用tf.train.Checkpoint来保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.lookup_ops import MutableHashTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以看到 x（AutoTrackable实例）的_gather_saveables_for_checkpoint方法并不会收集变量\n",
    "x._gather_saveables_for_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VARIABLE_VALUE': <tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.vvv._gather_saveables_for_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上，Checkpoint使用了ObjectGraphView类，遍历整个DAG节点，并调用`_gather_saveables_for_checkpoint`方法类收集可以被保存的对象以及它们的依赖关系并存储。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore-on-Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'test/Variable:0' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def assign(self, init=tf.constant([1., 2., 3.]), name=None):\n",
    "        with self.name_scope:\n",
    "          self.w = tf.Variable(init)\n",
    "    def operate(self, value):\n",
    "        self.w.assign_add(value)\n",
    "\n",
    "m = MyModule(name='test')\n",
    "m.assign()\n",
    "m.operate([1., 1., 1.])\n",
    "m.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ckpt.save.test-1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(module=m)\n",
    "ckpt.save('data/ckpt.save.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "module = MyModule(name='test')\n",
    "try:\n",
    "    module.w\n",
    "except AttributeError as e:\n",
    "    print(\"w doesn't exist.\")\n",
    "else:\n",
    "    print(\"w already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于没用调用assign方法，可以看到w属性是不存在的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1493ff080>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(module=module)\n",
    "ckpt.restore(tf.train.latest_checkpoint('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    module.w\n",
    "except AttributeError as e:\n",
    "    print(\"w doesn't exist.\")\n",
    "else:\n",
    "    print(\"w already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到由于w属性没有建立，因此restore之后，w依然是不存在的。但是当调用assign方法建立w属性的时候，restore就会起作用了，可以看到结果是restore得到的结果，并不是assign的参数所指定的`tf.constant([1., 1., 1.])`。  \n",
    "\n",
    "**Restore-on-Creation机制就是在权重没有建立时，暂时不加载checkpoint保存的权重，一旦建立，则立即加载。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'test/Variable:0' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.assign(tf.constant([1., 1., 1.]))\n",
    "module.w  # so you see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'test/Variable:0' shape=(3,) dtype=float32, numpy=array([2., 2., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.assign(tf.constant([2.,2.,2.]))\n",
    "module.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.variables`：收集所有变量；  \n",
    "`tf.trainable_variables`：收集所有可训练的变量；  \n",
    "`tf.submodules`：收集所有子模块，也就是依赖或者引用的tf.Module实例。\n",
    "\n",
    "> You can enter the name scope explicitly using `with self.name_scope:` or you can annotate methods(apart from `__init__`) with `@tf.Module.with_name_scope`.\n",
    "\n",
    "注意使用`@tf.Module.with_name_scope`或者`with self.name_scope`，必须在`__init__`中调用`super().__init__`，以此来调用`tf.Module`类的构建函数`__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[1.38661  , 1.6494907, 2.1893508],\n",
       "       [1.38661  , 1.6494907, 2.1893508],\n",
       "       [1.38661  , 1.6494907, 2.1893508],\n",
       "       [1.38661  , 1.6494907, 2.1893508],\n",
       "       [1.38661  , 1.6494907, 2.1893508],\n",
       "       [1.38661  , 1.6494907, 2.1893508]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dense(tf.Module):\n",
    "  def __init__(self, input_features, output_features, name=None):\n",
    "    super(Dense, self).__init__(name=name)\n",
    "    with self.name_scope:\n",
    "      self.w = tf.Variable(tf.random.normal([input_features, output_features], name='w'))\n",
    "      self.b = tf.Variable(tf.zeros([output_features,]), name='b')\n",
    "  @tf.Module.with_name_scope\n",
    "  def __call__(self, x):\n",
    "    self.test = tf.Variable([2.,3.], name='ahaha')\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)\n",
    "\n",
    "d = Dense(input_features=5, output_features=3, name='Jason')\n",
    "d(tf.ones([6, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jason/b:0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.variables[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jason/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.name_scope.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jason'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Jason/ahaha:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.test = tf.Variable([1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Jason/ahaha:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d(tf.ones([6, 5]))\n",
    "d.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jason',\n",
       " <tensorflow.python.framework.ops.name_scope_v2 at 0x149419208>,\n",
       " set(),\n",
       " True,\n",
       " -1,\n",
       " <tf.Variable 'Jason/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'Jason/ahaha:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>,\n",
       " <tf.Variable 'Jason/Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[ 2.2590709 ,  1.0981804 ,  0.7432608 ],\n",
       "        [-1.3432873 ,  0.5018356 , -0.0742505 ],\n",
       "        [ 0.1284043 , -0.6313724 , -0.18389162],\n",
       "        [ 0.7372214 ,  0.5132439 ,  0.25380427],\n",
       "        [-0.3947993 ,  0.16760309,  1.4504279 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d._flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.function 装饰器返回的是def_function.Function对象；\n",
    "* Function对象是由一个个的ConcreteFunction函数组成；ConcreteFunction对象是由包含了FunctionGraph和structured_input_signature；\n",
    "* FunctionGraph是tf.Graph的子类，strucured_input_signature是函数签名；\n",
    "* 如果传入的参数是一个python值，则会对每一个遇到的pyhon值创建一个ConcreteFunction，实际上python值会成为Graph的一个固定的值，如果创建ConcreteFunction时，参数是一个python的引用，则此时引用的值就被固定在Graph中；\n",
    "* 这也说明，如果是参数是可变了python值，那么，在函数中就不能运行原处改变的操作，因为该值已经被固定在Graph中了；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 运行函数的每一行代码，代码分为两类：\n",
    "  * 纯python代码；\n",
    "  * tensorflow代码，如`tf.add`，以及可以转换为计算节点的python代码；  \n",
    "运行的结果就是：纯python代码会与运行普通的python代码相同，tensorflow代码与可以转换为计算节点的python代码会构建为计算图。\n",
    "2. 运行计算图一次\n",
    "3. 基于函数的名字和输入的函数参数类型生成一个哈希值，并将计算的计算图缓存到一个哈希表中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AutoGraph与if，while循环：**  \n",
    "* for：如果iterable是张量，则转换；\n",
    "* while：如果while条件是张量，则转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add(x, y):\n",
    "    return tf.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-0.29873416, -2.1888025 , -1.5106347 ],\n",
       "       [ 0.49492085, -0.5007396 , -0.94732714]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(tf.random.normal((2, 3)), tf.random.normal((3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[ 0.7217116 ,  0.2724216 , -0.14417058, -0.10751617,  0.96084595,\n",
       "        -0.54465836],\n",
       "       [ 0.20024541, -0.9428696 , -0.64654046, -0.47454974,  1.4712204 ,\n",
       "        -0.38784763]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(tf.random.normal((2, 6)), tf.random.normal((6,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ConcreteFunction add(x, y) at 0x1499B3B38>,\n",
       " <ConcreteFunction add(x, y) at 0x1499B3860>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(6,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ConcreteFunction add(x, y) at 0x1499B3B38>,\n",
       " <ConcreteFunction add(x, y) at 0x1499B3860>,\n",
       " <ConcreteFunction add(x=6, y=9) at 0x1499EE9E8>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ConcreteFunction add(x, y) at 0x1499B3B38>,\n",
       " <ConcreteFunction add(x, y) at 0x1499B3860>,\n",
       " <ConcreteFunction add(x, y) at 0x10EB87860>,\n",
       " <ConcreteFunction add(x=6, y=9) at 0x1499EE9E8>,\n",
       " <ConcreteFunction add(x, y) at 0x10EB8C2E8>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions()  # 跟_list_all_concrete_functions_for_serialization的区别是啥？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2, 6), dtype=tf.float32, name='x'),\n",
       "  TensorSpec(shape=(6,), dtype=tf.float32, name='y')),\n",
       " {})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[0].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2, 3), dtype=tf.float32, name='x'),\n",
       "  TensorSpec(shape=(3,), dtype=tf.float32, name='y')),\n",
       " {})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[1].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 9), {})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[2].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参数是python值所对应的ConcreteFunction函数不需要传入参数了，因为参数值已经固定在里面了\n",
    "# 注意下标是python值6和9为参数的ConcreteFunction\n",
    "add._list_all_concrete_functions_for_serialization()[2]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ConcreteFunction add(x, y) at 0x1499B3B38>,\n",
       " <ConcreteFunction add(x, y) at 0x1499B3860>,\n",
       " <ConcreteFunction add(x=6, y=9) at 0x1499EE9E8>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2, 6), dtype=tf.float32, name='x'),\n",
       "  TensorSpec(shape=(6,), dtype=tf.float32, name='y')),\n",
       " {})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = add._list_all_concrete_functions_for_serialization()[0].structured_input_signature\n",
    "sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_concrete_function`获取ConcreteFunction，奇怪的是两种方式获得ConcreteFunction并不相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction add(x, y) at 0x1499FE6D8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = add.get_concrete_function(tf.TensorSpec(shape=[2,6], dtype=tf.float32), tf.TensorSpec(shape=[6,], dtype=tf.float32))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2, 6), dtype=tf.float32, name='x'),\n",
       "  TensorSpec(shape=(6,), dtype=tf.float32, name='y')),\n",
       " {})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[0].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction add(x, y) at 0x1499B3B38>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.function只允许在第一次调用函数时，创建tf.Variable；因此典型用法应当是在`__init__`方法中设置权重为`None`，然后在`build`方法中加以判断，如果权重为`None`，则初始化权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = None\n",
    "\n",
    "def f(x):\n",
    "    global v\n",
    "    if v is None:\n",
    "      v = tf.Variable(x)\n",
    "    return v\n",
    "f = tf.function(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(tf.constant([2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(tf.constant([2., 3.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我把v重新设置成None时，导致再次调用函数f时会试图创建variable，因此抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError when create variable non-first call\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v = None\n",
    "    f(tf.constant([1.,2, 3.]))\n",
    "except ValueError:\n",
    "    print(\"ValueError when create variable non-first call\")\n",
    "else:\n",
    "    print(\"isn't ok?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确的用法应当是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name, units=10):\n",
    "        super(MyModule, self).__init__(name=name)\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.units = units\n",
    "    @tf.Module.with_name_scope\n",
    "    def build(self, input_shape):\n",
    "        if self.w is None:\n",
    "            self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]))\n",
    "        if self.b is None:\n",
    "            self.b = tf.Variable(tf.random.normal([self.units, ]))\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.w) + self.b\n",
    "    @tf.function\n",
    "    def __call__(self, input):\n",
    "        self.build(input.shape)\n",
    "        return self.call(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 10])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyModule('testModule')\n",
    "input = tf.random.normal([5,3])\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(5, 3), dtype=tf.float32, name='input'),), {})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.__call__._list_all_concrete_functions_for_serialization()[0].structured_input_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果注释掉`build`方法中的两个`if`判断语句，导致`ValueError when create variable non-first call`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可变类型作为函数的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    print(x)\n",
    "    # 这一行会导致错误，也就是说参数是可变类型的原处操作会导致运行错误\n",
    "    # x.append(100) \n",
    "    return x[-1] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.,2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=102.0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=102.0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.get_concrete_function(x)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([1.0, 2.0],), {})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()[0].structured_input_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到上面的例子说明：python的可变类型作为参数时，除了不能用原处操作的方法外，其他的和python值作为参数时是相同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个例子来自于TensorFlow 2官方文档："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [] \n",
    "@tf.function \n",
    "def f(x): \n",
    "  for i in x: \n",
    "    print(i)\n",
    "    l.append(i)    # Caution! Will only happen once when tracing \n",
    "f([1, 2, 3])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([1,2,3])\n",
    "l  # 第二次调用并没有改变l的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"while/TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "f(tf.constant([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'while/TensorArrayV2Read/TensorListGetItem:0' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l  # 换了参数类型后，print语句也不会再运行了，意外的是append语句居然执行了，得到了奇怪的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction f(x) at 0x14AB559B0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'while/TensorArrayV2Read/TensorListGetItem:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'while/TensorArrayV2Read/TensorListGetItem:0' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "@tf.function\n",
    "def f(a):\n",
    "    for i in range(a):\n",
    "        l.append(0)  # 只会在构建计算图时运行一次\n",
    "        tf.print(a)  # 会成为计算图的一个计算节点，每次调用都会运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)  # 第二次调用并不会改变list的值，因为第二次只会运行计算图\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义类的序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, age):\n",
    "        self.age = age\n",
    "\n",
    "@tf.function\n",
    "def f(year, p):\n",
    "    print(year)\n",
    "    return p.age + year\n",
    "\n",
    "p = Person(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=101>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=102>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=102>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, <tensorflow.python.framework.func_graph.UnknownArgument at 0x14adadfd0>),\n",
       " {})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.get_concrete_function(2,p).structured_input_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可能是由于Person类并没有序列化，因此导致`_list_all_concrete_functions_for_serialization`并不能获取`ConcreteFunction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((1, <tensorflow.python.framework.func_graph.UnknownArgument object at 0x14ab55ac8>), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((2, <tensorflow.python.framework.func_graph.UnknownArgument object at 0x14adadfd0>), {}).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([5, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=535, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def concat_with_padding():\n",
    "    x = tf.zeros([5, 10])\n",
    "    tf.print(x.shape)\n",
    "    x = x[:4]\n",
    "    tf.print(x.shape)\n",
    "    for i in tf.range(4):\n",
    "        x = tf.concat([x[:i], tf.ones([1, 10])], axis=0) # 循环时张量形状不能改变\n",
    "        tf.print(x.shape)\n",
    "        x.set_shape([4, 10])\n",
    "        tf.print(x.shape)\n",
    "    return x\n",
    "concat_with_padding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x08\\x01\\x12\\x04\\x12\\x02\\x08\\x02\"\\x08\\x00\\x00@@\\x00\\x00\\xc0@'>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([3.,6.])\n",
    "a = tf.io.serialize_tensor(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.parse_tensor(a, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `drop_remainder=True`：如果最后一个批次样本数不足，则弃之不用\n",
    "* 常用顺序 `train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()`\n",
    "* train.prefetch(2)  提前取出两个样本放入内存\n",
    "* train.batch(20).prefetch(2)  提前取出2个批次放入内存，prefetch方法一般写在最后"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.data.Dataset.range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=550, shape=(), dtype=int64, numpy=1>,\n",
       " <tf.Tensor: id=551, shape=(), dtype=int64, numpy=2>,\n",
       " <tf.Tensor: id=552, shape=(), dtype=int64, numpy=3>,\n",
       " <tf.Tensor: id=553, shape=(), dtype=int64, numpy=4>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3]\n",
    "b = tf.data.Dataset.range(4, 5)  # ==> [ 4,]\n",
    "c = a.concatenate(b)\n",
    "list(iter(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.data.Dataset.from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " (<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.12994805,  0.32083076, -0.3990724 ], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=99.0>))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices((tf.random.normal([4, 3]), [99., 0, 1, 0]))\n",
    "next(iter(a.enumerate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a': 1, 'b': 3, 'c': 10}, 100)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(({\"a\": [1, 2, 20], \"b\": [3, 4, 20], \"c\":[10,11, 20]}, [100,200,300]))\n",
    "next(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 还有这个不同，啊哈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices([ [1, 2, 3], [4, 5, 6], [7, 8, 9] ])\n",
    "next(iter(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=592, shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: id=593, shape=(), dtype=int32, numpy=4>,\n",
       " <tf.Tensor: id=594, shape=(), dtype=int32, numpy=7>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices(( [1, 2, 3], [4, 5, 6], [7, 8, 9] ))\n",
    "next(iter(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.data.Dataset.from_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor takes a callable as input, not an iterator. This allows it to restart the generator when it reaches the end. It takes an optional args argument, which is passed as the callable's arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(stop):\n",
    "  i = 0\n",
    "  while i<stop:\n",
    "    yield i\n",
    "    i += 1\n",
    "tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes = (), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 3, 4, 5, 6], [1, 2], [1, 2], [1, 2, 3, 4], [1, 2], [1, 2, 3]]\n",
    "\n",
    "d = tf.data.Dataset.from_generator(lambda: x, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个批次形状不一样，所以错误\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    next(iter(d.batch(2)))\n",
    "except:\n",
    "    print(\"一个批次形状不一样，所以错误\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33129, shape=(2, 6), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4, 5, 6],\n",
       "       [1, 2, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = d.padded_batch(2, [-1])\n",
    "next(iter(dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: <unknown>, types: tf.int32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_generator(generator=lambda: [3,4,5], output_types=tf.int32)  # generator必须是callable，并返回支持iter方法的对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.data.Dataset.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset.map方法是以图模式运行的，Dataset.map接受的是一个Tensor而不是EagerTensor，因此不能直接使用EagerTensor.numpy方法，如果要用.numpy方法，则需要tf.py_function包装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'foo', b'bar', b'baz)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz)\")]\n",
    "dataset = tf.data.Dataset.from_generator(lambda: elements, (tf.int32, tf.string))\n",
    "result = dataset.map(lambda x_int, y_str: y_str)\n",
    "list(result.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'1-foo', b'2-bar', b'3-baz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements =  ([{\"a\": 1, \"b\": \"foo\"}, {\"a\": 2, \"b\": \"bar\"}, {\"a\": 3, \"b\": \"baz\"}])\n",
    "dataset = tf.data.Dataset.from_generator(lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
    "result = dataset.map(lambda d: tf.strings.as_string(d[\"a\"]) +'-' + d[\"b\"])\n",
    "tmp = list(result.as_numpy_iterator())\n",
    "list(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': array([1, 2], dtype=int32), 'b': array([b'foo', b'bar'], dtype=object)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset.batch(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x): return x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements =  ([{\"a\": 1, \"b\": \"foo\"}, {\"a\": 2, \"b\": \"bar\"}, {\"a\": 3, \"b\": \"baz\"}])\n",
    "dataset = tf.data.Dataset.from_generator(lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
    "#result = dataset.map(lambda x: x['a'])\n",
    "result = dataset.map(lambda x: tf.py_function(func=test, inp=[x['a']], Tout=tf.int32))\n",
    "list(result.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.data.TFRecordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observations = int(1e4)\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0,f1,f2,f3 = feature0[0], feature1[0], feature2[0], feature3[0]\n",
    "def serialize_example(f0,f1,f2,f3):\n",
    "    f2 = isinstance(f2, type(tf.constant(0))) and f2.numpy() or f2  # BytesList won't unpack a string from an EagerTensor.\n",
    "    feature = {\n",
    "      'feature0': tf.train.Feature(int64_list=tf.train.Int64List(value=[f0])),\n",
    "      'feature1': tf.train.Feature(int64_list=tf.train.Int64List(value=[f1])),\n",
    "      'feature2': tf.train.Feature(bytes_list=tf.train.BytesList(value=[f2])),\n",
    "      'feature3': tf.train.Feature(float_list=tf.train.FloatList(value=[f3])),\n",
    "  }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def tf_serialize_example(f0,f1,f2,f3):\n",
    "    example_string = tf.py_function(serialize_example, (f0,f1,f2,f3), tf.string)\n",
    "    #return tf.reshape(example_string, ())  # 这样子返回的是tf.string类型的Tensor\n",
    "    return example_string  # 这样子返回的是bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64_list {\n",
       "  value: 0\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Feature(int64_list=tf.train.Int64List(value=[f0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 序列化Example对象与重建Example对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = {\n",
    "      'feature0': tf.train.Feature(int64_list=tf.train.Int64List(value=[f0])),\n",
    "      'feature1': tf.train.Feature(int64_list=tf.train.Int64List(value=[f1])),\n",
    "      'feature2': tf.train.Feature(bytes_list=tf.train.BytesList(value=[f2])),\n",
    "      'feature3': tf.train.Feature(float_list=tf.train.FloatList(value=[f3])),\n",
    "  }\n",
    "example_proto = tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\nQ\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xfci\\x94?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = example_proto.SerializeToString()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Example.FromString(a) == example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = tf.train.Example()\n",
    "example.ParseFromString(a)\n",
    "example == example_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFRecord的Dataset写入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature0': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 1, 0])>,\n",
       " 'feature1': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 3])>,\n",
       " 'feature2': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'cat', b'horse'], dtype=object)>,\n",
       " 'feature3': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 1.1594844 , -0.17166306, -1.4441673 ], dtype=float32)>}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((feature0[:3], feature1[:3], feature2[:3], feature3[:3]))\n",
    "dataset = dataset.map(tf_serialize_example)\n",
    "writer1 = tf.data.experimental.TFRecordWriter(\"data/test_1.tfrecord\")\n",
    "writer1.write(dataset)\n",
    "tf.io.parse_example(list(dataset), feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xfci\\x94?'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04q\\xc8/\\xbe'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'\\nS\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04y\\xda\\xb8\\xbf'>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature0': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 1, 0])>,\n",
       " 'feature1': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 0, 2])>,\n",
       " 'feature2': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'horse', b'cat', b'chicken'], dtype=object)>,\n",
       " 'feature3': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.71525556, -0.7446053 ,  1.4935725 ], dtype=float32)>}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((feature0[3:6], feature1[3:6], feature2[3:6], feature3[3:6]))\n",
    "dataset = dataset.map(tf_serialize_example)\n",
    "writer2 = tf.data.experimental.TFRecordWriter(\"data/test_2.tfrecord\")\n",
    "writer2.write(dataset)\n",
    "tf.io.parse_example(list(dataset), feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 读取TFRecord文件到Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature0': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 1, 0, 0, 1, 0])>,\n",
       " 'feature1': <tf.Tensor: shape=(6,), dtype=int64, numpy=array([3, 0, 2, 0, 0, 3])>,\n",
       " 'feature2': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
       " array([b'horse', b'cat', b'chicken', b'cat', b'cat', b'horse'],\n",
       "       dtype=object)>,\n",
       " 'feature3': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
       " array([ 0.71525556, -0.7446053 ,  1.4935725 ,  1.1594844 , -0.17166306,\n",
       "        -1.4441673 ], dtype=float32)>}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [\"data/test_2.tfrecord\", \"data/test_1.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(files)\n",
    "\n",
    "tf.io.parse_example(list(dataset), feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_single_example(example):\n",
    "    return tf.io.parse_single_example(example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       "  'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>,\n",
       "  'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>,\n",
       "  'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=0.71525556>},\n",
       " {'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       "  'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       "  'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'cat'>,\n",
       "  'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=-0.7446053>}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.map(_parse_single_example).take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.map(_parse_single_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [tf.feature_column.numeric_column('feature1'), tf.feature_column.numeric_column('feature0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = layers.DenseFeatures(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature0': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>,\n",
       "  'feature1': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([3, 0])>,\n",
       "  'feature2': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'horse', b'cat'], dtype=object)>,\n",
       "  'feature3': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.71525556, -0.7446053 ], dtype=float32)>}]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list(d.batch(2).take(1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 3.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df(b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 写入文件的另一种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter('data/test.tfrecord') as writer:\n",
    "    for i in dataset:\n",
    "        writer.write(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature0': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>,\n",
       " 'feature1': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2])>,\n",
       " 'feature2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'chicken'], dtype=object)>,\n",
       " 'feature3': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7652261], dtype=float32)>}"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.parse_example(list(tf.data.TFRecordDataset(['data/test.tfrecord']).take(1)), feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.ragged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方文档：https://tensorflow.google.cn/guide/ragged_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[6, 4, 7, 4], [], [8, 12, 5], [9], []]>\n",
      "tf.Tensor([2.25              nan 5.33333333 6.                nan], shape=(5,), dtype=float64)\n",
      "<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], [], [5, 3]]>\n",
      "<tf.RaggedTensor [[3, 1, 4, 1, 3, 1, 4, 1], [], [5, 9, 2, 5, 9, 2], [6, 6], []]>\n",
      "<tf.RaggedTensor [[b'So', b'lo'], [b'th', b'fo', b'al', b'th', b'fi']]>\n"
     ]
    }
   ],
   "source": [
    "digits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
    "words = tf.ragged.constant([[\"So\", \"long\"], [\"thanks\", \"for\", \"all\", \"the\", \"fish\"]])\n",
    "print(tf.add(digits, 3))\n",
    "print(tf.reduce_mean(digits, axis=1))\n",
    "print(tf.concat([digits, [[5, 3]]], axis=0))\n",
    "print(tf.tile(digits, [1, 2]))\n",
    "print(tf.strings.substr(words, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[9, 1, 16, 1], [], [25, 81, 4], [36], []]>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ragged.map_flat_values(tf.math.square, digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1, 4, 1], [], [5, 9, 2], [6], []]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9], [2]]>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.RaggedTensor.from_value_rowids(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2],\n",
    "    value_rowids=[0, 0, 0, 0, 2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9], [2]]>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.RaggedTensor.from_row_lengths(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2],\n",
    "    row_lengths=[4, 0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9], [2]]>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.RaggedTensor.from_row_splits(\n",
    "    values=[3, 1, 4, 1, 5, 9, 2],\n",
    "    row_splits=[0, 4, 4, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.TensorArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x141f0af98>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.TensorArray(dtype=tf.float32, size=3, infer_shape=False, clear_after_read=False)\n",
    "a = tf.random.normal([3,2,2])\n",
    "x.unstack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=602, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.10629629, -0.19466183],\n",
       "       [-0.4460331 , -0.47419053]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=606, shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[-1.2129303 ,  0.77940047],\n",
       "        [-0.21802388,  0.98266596]],\n",
       "\n",
       "       [[ 1.740146  , -0.34278297],\n",
       "        [-1.3144659 ,  1.0175093 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gather([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=609, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.740146  , -0.34278297],\n",
       "       [-1.3144659 ,  1.0175093 ]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.scatter([2,1,0], a)\n",
    "y.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x141f0a438>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([5,6])\n",
    "x.split(a, [1,2,2]) # 长度分别是1，2，2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=620, shape=(1, 6), dtype=float32, numpy=\n",
       "array([[-3.5588963 , -1.5443984 , -0.6560149 ,  0.4804773 , -0.9900909 ,\n",
       "         0.86643726]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=621, shape=(2, 6), dtype=float32, numpy=\n",
       "array([[-0.48379177,  1.3902569 ,  0.03354906, -0.9551902 ,  1.7645974 ,\n",
       "        -0.33056656],\n",
       "       [ 0.79169416, -0.74314564,  1.0771104 ,  0.33629403, -1.1552415 ,\n",
       "         0.78788143]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "使用`tf.function`一章中的`MyModule`类的实例`m`展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x1422696d8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.save(m, \"data/modelDir\")\n",
    "tf.saved_model.load(\"data/modelDir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.random.categorical(tf.math.log([[0.1,0.3,0.6]]), 1000)  # 参数可以是log后的概率值，这个写法会以0.1，0.3，0.6的概率从多项式分布中随机抽取\n",
    "x = tf.random.categorical(tf.math.log([[1., 2. , 6.]]), 1000) # 概率分别是[1., 2., 6.]/tf.reduce_sum([1., 2. 6.])\n",
    "# 换一种说法就是，按照参数tf.exp变换后所占的比例作为随机抽样的概率，相当于对参数做了softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=103>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.cast(x==0, tf.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint只保存模型的参数，不保存模型的计算过程，因此一般用于在具有模型源码的时候恢复之前训练好的模型参数。\n",
    "```python3\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.save(save_path_with_prefix)\n",
    "```\n",
    "* 这里tf.train.Checkpoint接受的参数比较特殊，是一个\\*\\*kwargs。具体而言，是一系列键值对，键名可以随便起，值为需要保存的对象。\n",
    "* `save_path_with_prefix`是保存文件的目录+前缀。例如在`checkpoint.save(\"./save/model.ckpt\")`，在save目录下会建立三个文件：`checkpoint, model.ckpt-1.index, model.ckpt-1.data-00000-of-00001`，这些文件记录了变量信息。`checkpoint.save`可以运行多次，每次运行都会得到一个`.index`文件和`.data`文件，序号一次累加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续训练模型可以用一下方式实现：\n",
    "```\n",
    "checkpoint = tf.train.Checkpoint(myAwesomeModel=model, myAwesomeOptimizer=optimizer)\n",
    "checkpoint.save(save_path_with_prefix)\n",
    "model_to_be_restored = MyModel() \n",
    "checkpoint = tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)\n",
    "checkpoint.restore(save_path_with_prefix_and_index)\n",
    "```\n",
    "* `save_path_with_prefix_and_index`是之前保存到文件的目录+前缀+编号。例如，调用`checkpoint.restore(\"./save/model.ckpt-1\")`，序号为1的文件来恢复模型。\n",
    "\n",
    "```\n",
    "tf.train.latest_checkpoint(save_path)\n",
    "```\n",
    "* 返回最近一次的checkpoint的文件名，比如返回`./save/model.ckpt-10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ckpt.save.test-1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: \"aaaa\"\n",
       "value: \"cccc\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_1 = tf.constant('aaaa')\n",
    "#x0 = tf.train.Feature(bytes_list=tf.train.BytesList(value=[value])) \n",
    "# BytesList won't unpack a string from an EagerTensor.\n",
    "if isinstance(value_1, type(tf.constant(0))):\n",
    "    value_1 = value_1.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "a = tf.train.BytesList(value=[value_1, b'cccc'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes_list {\n",
       "  value: \"aaaa\"\n",
       "  value: \"cccc\"\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(['aaaa', 'cccc'])\n",
    "x = x.numpy() \n",
    "x0 = tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'aaaa', b'cccc']))\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_2 = tf.constant([4., 5.])\n",
    "x1 = tf.train.Feature(float_list=tf.train.FloatList(value=value_2))\n",
    "value_3 = tf.constant([2, 3])\n",
    "x2 = tf.train.Feature(int64_list=tf.train.Int64List(value=value_3))\n",
    "feature = {'x1':x1, 'x2':x2, 'x0':x0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  key: \"x0\"\n",
       "  value {\n",
       "    bytes_list {\n",
       "      value: \"aaaa\"\n",
       "      value: \"cccc\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"x1\"\n",
       "  value {\n",
       "    float_list {\n",
       "      value: 4.0\n",
       "      value: 5.0\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"x2\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 2\n",
       "      value: 3\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Features(feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"x0\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"aaaa\"\n",
       "        value: \"cccc\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"x1\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 4.0\n",
       "        value: 5.0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"x2\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 2\n",
       "        value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "如果深度学习模型的权重初始化得太小，那信号将在每层间传递时逐渐缩小而难以产生作用；如果权重初始化的太大，那信号将在每层间传递时逐渐放大并导致发散和失效。  \n",
    "Xavier初始化器让初始化权重满足均值为0，方差为$\\frac{2}{N_{in}+N_{out}}$均匀分布或者高斯分布；\n",
    "\n",
    "* `tf.initializers.glorot_normal()(shape=[20,30])`：创建 $N_{in}=20,N_{out}=30$ 服从正态分布的的初始化权重；\n",
    "* `tf.initializers.glorot_uniform()(shape=[20,30]`：与上面相同，只是服从的是均匀分布。\n",
    "\n",
    "也可以通过下面的api间接实现：  \n",
    "* `tf.random_normal_initializer(mean=0.0,stddev=0.05)(shape=[])`\n",
    "* `tf.random_uniform_initializer(minval=-0.05, maxval=0.05)(shape=[])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "matrix_band_part(input, num_lower, num_upper)\n",
    "```\n",
    "* num_lower: 下三角要保留的对角线数，-1表示全保留；num_upper类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.529435  ,  0.8286487 ,  1.837228  ,  0.09473267],\n",
       "       [ 0.36858612,  1.0950916 ,  0.62635964,  1.1934665 ],\n",
       "       [-0.7357971 ,  0.18043841, -0.19846489, -0.9738333 ],\n",
       "       [-1.5683837 ,  2.8496115 ,  0.01234788, -0.76184636]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.529435  ,  0.8286487 ,  1.837228  ,  0.09473267],\n",
       "       [ 0.        ,  1.0950916 ,  0.62635964,  1.1934665 ],\n",
       "       [ 0.        ,  0.        , -0.19846489, -0.9738333 ],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.76184636]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(x, 0, -1)  # 变成下三角矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.argmax_v2(input, axis=None, output_type=tf.int64, name=None)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_std # 标准差\n",
    "tf.math.reduce_variance # 方差\n",
    "tf.math.reduce_all\n",
    "tf.math.reduce_any\n",
    "tf.math.reduce_logsumexp # 相当于 tf.math.log(tf.reduce_sum(tf.exp(x)))\n",
    "tf.math.argmin\n",
    "tf.math.argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`tf.matmul(a, b)`  # 将最后两个维度用与矩阵乘法，前面的维度必须完全相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "在tf.GradientTape上下文中执行的所有操作记录下来，用于计算梯度。默认情况下，tf.GradientTape持有的资源会在调用GradientTape.gradient()方法后立即释放。要在同一计算中计算多个梯度，需要创建一个持久梯度带，这允许多次调用gradient()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=770, shape=(), dtype=float32, numpy=108.0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "  t.watch(x)  # 由于x是常数，所以要调用调用watch方法，如果是Variable则不需要这一行\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "dz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
    "dy_dx = t.gradient(y, x)  # 6.0\n",
    "del t  # Drop the reference to the tape\n",
    "dz_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "在上下文中的梯度计算也会被记录下来，因此可以实现高阶梯度计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * x * x\n",
    "    dy_dx = t2.gradient(y,x)\n",
    "d2y_dx2 = t.gradient(dy_dx, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assert dy_dx.numpy() == 3.0\n",
    "assert d2y_dx2.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * 8.\n",
    "    y = x * x\n",
    "dydx = tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=824, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dydx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
    "```\n",
    "* 其中y_true是系数矩阵，直接的label，而不是one-hot向量\n",
    "* from_logits=False时，y_pred是tf.nn.softmax输出结果，也就是每一个元素都是概率，每一行之和为1\n",
    "* from_logits=True时，y_pred是上一层的输出结果，也就是说softmax(y_pred)运算在此函数内执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "两分类的交叉熵计算，可以看到下面三种计算方式结果一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=849, shape=(), dtype=float32, numpy=0.27290332>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.binary_crossentropy([1,0,1], [0.9,0.3,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876, shape=(), dtype=float32, numpy=0.27290332>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.losses.binary_crossentropy([[1],[0],[1]], [[0.9],[0.3],[0.7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=892, shape=(), dtype=float32, numpy=0.27290347>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.multiply(tf.subtract(1.,[1,0,1.]), tf.math.log(tf.subtract(1.,[0.9,0.3,0.7])))\n",
    "b = tf.multiply([1,0,1.], tf.math.log([0.9,0.3,0.7]))\n",
    "-tf.reduce_mean(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "tf.metrics.categorical_accuracy(y_true, y_pred)\n",
    "* y_true是one-hot向量；y_pred是softmax输出\n",
    "\n",
    "tf.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "* y_true 是系数Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1., 1, 0, 0])\n",
    "b = tf.constant([0.98, 1, 0, 0.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=922, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.BinaryAccuracy(threshold=0.55)(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=934, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.binary_accuracy(a, tf.where(b>0.55, 1., 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=941, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.binary_accuracy(a, b, 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tf.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "optimizer.apply_gradient(zip(grads, model.trainable_variables))\n",
    "# .apply_gradient(grads_and_vars)\n",
    "# grads_and_vars: List of (gradient, variable) pairs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([6,3])\n",
    "b = tf.constant([2,1,1,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: id=950, shape=(6, 2), dtype=float32, numpy=\n",
       "array([[-0.16724938, -0.41634324],\n",
       "       [ 0.053495  , -0.25219882],\n",
       "       [-0.28541866, -0.3039618 ],\n",
       "       [ 0.5407113 , -0.07260029],\n",
       "       [ 0.83685905, -0.5499403 ],\n",
       "       [ 0.864015  ,  0.46615827]], dtype=float32)>, indices=<tf.Tensor: id=951, shape=(6, 2), dtype=int32, numpy=\n",
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [0, 1]], dtype=int32)>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.top_k(a,  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=953, shape=(6,), dtype=bool, numpy=array([False,  True, False,  True,  True,  True])>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.in_top_k(b, a,  2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "tf.nn.moments(x, axes, keep_dims=False)\n",
    "# 若axes=[0,1,2]，则沿着[0,1,2]轴计算mean和variance\n",
    "# keep_dims 返回的结果是否保持原来的维度\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = tf.random.normal([128, 32, 32, 64])\n",
    "m, v = tf.nn.moments(x, [0,1,2], keepdims=True)\n",
    "assert m.shape == [1,1,1,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 相当于\n",
    "m2 = tf.reduce_mean(x, axis=[0,1,2], keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_all(m == m2).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.batch_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```pthon\n",
    "tf.nn.batch_normalization(x, mean, variance, offset, scale, variance_epsilion)\n",
    "```\n",
    "* mean, variance可以是`tf.nn.moments`的输出结果\n",
    "* 计算公式：\n",
    "```\n",
    "tmp = (x-mean)/tf.sqrt(variance + variance_epsilon)\n",
    "return tmp * scale + offset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.keras.layers.BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')\n",
    "```\n",
    "* axis：要标准化的特征轴\n",
    "* momentum：移动平均系数\n",
    "* epsilon：同上面的variance_epsilon\n",
    "* scale：是否乘上scale\n",
    "* center：是否加上offset\n",
    "* gamma：同上面scale\n",
    "* beta：同上面offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "设当前层norm的状态为：移动平均值$\\mu$，标准差$\\sigma$；当前mini-batch样本的均值和标准差分别为：$\\mu_i,\\sigma_i$；  系数为$\\alpha$，也就是1 - norm.momentum；则\n",
    "$$\n",
    "\\mu = (1-\\alpha)\\mu + \\alpha \\mu_i \\\\\n",
    "\\sigma = (1-\\alpha)\\sigma + \\alpha\\sigma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization_1/moving_mean:0' shape=(5,) dtype=float32, numpy=\n",
       "array([-5.5041215e-05, -2.2435044e-03,  4.9383932e-04,  3.6231871e-04,\n",
       "        7.5543998e-04], dtype=float32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.random.normal([3, 4, 5])\n",
    "norm = layers.BatchNormalization()\n",
    "norm(tmp, training=True)\n",
    "norm.moving_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### [参考这篇文献](https://arxiv.org/pdf/1702.03275.pdf)，其计算过程大概如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([6,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.9958078 , -1.1161667 ,  0.5356532 ],\n",
       "       [-1.4961139 , -0.51845664,  0.5639002 ],\n",
       "       [ 1.5387233 , -0.23743649,  0.7263154 ],\n",
       "       [ 2.2434304 , -1.1048131 , -0.6543047 ],\n",
       "       [-1.310277  , -0.43914226,  0.15493158],\n",
       "       [ 0.05232201,  0.90955174,  0.10727721]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.33731544, -0.41774392,  0.23896213], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.9445854 , 0.46078062, 0.20890851], dtype=float32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.moments(a, axes=0) # 计算均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.47209084, -1.027781  ,  0.64757395],\n",
       "       [-1.3144346 , -0.14820623,  0.70922744],\n",
       "       [ 0.86132157,  0.26533574,  1.0637237 ],\n",
       "       [ 1.366545  , -1.0110734 , -1.9496927 ],\n",
       "       [-1.1812032 , -0.03148925, -0.18340966],\n",
       "       [-0.20431943,  1.9532139 , -0.2874227 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = layers.BatchNormalization()\n",
    "norm(a, training=True)  #设置权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/moving_mean:0' shape=(3,) dtype=float32, numpy=array([ 0.00337315, -0.00417744,  0.00238962], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.moving_mean # 初始化值为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/moving_variance:0' shape=(3,) dtype=float32, numpy=array([1.0094459, 0.9946078, 0.9920891], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.moving_variance # 初始化值为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "参数的更新计算方式与下面的计算方式相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.00337315, -0.00417744,  0.00238962], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum * 0 + tf.nn.moments(a, axes=0)[0] * (1-norm.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.0094459, 0.9946078, 0.9920891], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum * 1. + tf.nn.moments(a, axes=0)[1] * (1-norm.momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### `training=False`时计算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.9872914 , -1.1144394 ,  0.5351159 ],\n",
       "       [-1.491716  , -0.51541233,  0.563461  ],\n",
       "       [ 1.5273933 , -0.233773  ,  0.72644037],\n",
       "       [ 2.2284482 , -1.1030607 , -0.6589753 ],\n",
       "       [-1.3068422 , -0.43592322,  0.1530718 ],\n",
       "       [ 0.04869518,  0.9157424 ,  0.10525191]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.98729146, -1.1144394 ,  0.53511584],\n",
       "       [-1.491716  , -0.51541233,  0.56346095],\n",
       "       [ 1.5273933 , -0.23377301,  0.7264403 ],\n",
       "       [ 2.2284482 , -1.1030607 , -0.6589753 ],\n",
       "       [-1.3068422 , -0.4359232 ,  0.1530718 ],\n",
       "       [ 0.04869518,  0.91574246,  0.10525191]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#等同于下面的计算：\n",
    "(a-norm.moving_mean)/(norm.moving_variance+norm.epsilon)**0.5 * norm.gamma+norm.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### `training=True`时的计算方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "我猜测应该是按照下面的方式计算的，不过好像数值有一点差距，暂且不管了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1130, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.384481  , -0.63107145,  0.46387953],\n",
       "       [ 0.4694243 , -0.13331562, -0.14479882],\n",
       "       [-1.5926844 , -0.25282156,  1.5538405 ],\n",
       "       [-0.37832326, -1.2666231 ,  0.35448807],\n",
       "       [ 1.6368306 ,  0.33443055, -0.5074017 ],\n",
       "       [-0.5197283 ,  1.9494011 , -1.7200075 ]], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a-tf.nn.moments(a, axes=0)[0])/(tf.nn.moments(a, axes=0)[1] + norm.epsilon)**0.5 * norm.gamma + norm.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1159, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.384481  , -0.6310714 ,  0.46387953],\n",
       "       [ 0.4694243 , -0.13331562, -0.14479882],\n",
       "       [-1.5926844 , -0.25282156,  1.5538404 ],\n",
       "       [-0.37832326, -1.2666233 ,  0.35448807],\n",
       "       [ 1.6368306 ,  0.33443055, -0.5074017 ],\n",
       "       [-0.5197283 ,  1.9494009 , -1.7200077 ]], dtype=float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1168, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.3310644e-04, 9.9297631e-01, 6.6906218e-03],\n",
       "       [4.5094042e-05, 6.6925492e-03, 9.9326235e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[ 3., 11.,  6.],[ 6., 11., 16.]])\n",
    "tf.nn.softmax(x)\n",
    "# 相当于：tf.exp(x)/tf.expand_dims(tf.reduce_sum(tf.exp(x), axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "```\n",
    "* 计算交叉熵，输入是softmax的输入，也就是说softmax的计算是在此函数的内部完成的；\n",
    "* 注意返回是的一个batch的所有样本组成的向量，要求交叉熵，还要使用tf.reduce_sum；\n",
    "* logits:神经网络最后一层的输出，维度是`[batch_size, num_classes]`，如果是单个样本那维度就是num_classes；\n",
    "* labels:样本的实际标签，维度与上面相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1177, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.3310644e-04, 9.9297631e-01, 6.6906218e-03],\n",
       "       [4.5094042e-05, 6.6925492e-03, 9.9326235e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[ 3., 11.,  6.],[ 6., 11., 16.]])\n",
    "tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1181, shape=(2,), dtype=float32, numpy=array([0.0070485 , 0.00676046], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sparse_softmax_cross_entropy_with_logits([1,2], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1220, shape=(2,), dtype=float32, numpy=array([0.0070485 , 0.00676046], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits(tf.one_hot([1,2], depth=3), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1232, shape=(2,), dtype=float32, numpy=array([0.00704847, 0.00676045], dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- tf.reduce_sum(tf.math.log(tf.nn.softmax(x)) * tf.one_hot([1,2], depth=3), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.nn.conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.nn.conv2d(input, filters, strides, padding, data_format='NHWC', dilations=None, name=None)\n",
    "```\n",
    "* 第一个参数input，要求shape必须满足`[batch, in_height, in_weight, in_channels]`，具体的含义是`[训练时一个batch的图片数量，图片高度，图片宽度，图像通道数]`\n",
    "* 第二个参数filters是卷积核，要求shape必须满足`[filter_height,filter_width,in_channels,out_channels]`，具体的含义是`[卷积核的高度，卷积核的宽度，图像的通道数，卷积核的个数]`\n",
    "* \n",
    "* 第三个参数strides，卷积时在图像每一维的步长，这是一个一维张量，对于图片来说，`strides=[1, x, y, 1]，strides[0]==strides[3]==1`；\n",
    "* 第四个参数padding，string类型的量，只能是“SAME”，“VALID”其中之一，这个值决定了不同的卷积方式， padding=\"SAME\"表示有padding，前后补0，保证行列数不变，padding=\"VALID\"表示不加padding；\n",
    "* 第五个参数，use_cudnn_on_gpu: bool类型，是否使用cudnn加速；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 7, 7, 2])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = layers.Conv2D(filters=2, kernel_size=[4,4])\n",
    "x = tf.random.normal([6, 10, 10, 3])\n",
    "t(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 3, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.variables[0].shape # 卷积核权重的个数，每个卷积核大小为[height,width,in_channels]，卷积核的个数为out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.variables[1].shape # 卷积运算的bias个数，每个卷积核对应一个bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = tf.io.read_file('data/TheStarryNight.jpg')\n",
    "arr_img = tf.image.decode_jpeg(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.image.adjust_brightness(arr_img, 0.2)  # 计算方式：arr_img - 0.2 * 255, 调整亮度，负数的话是减小亮度\n",
    "tf.image.adjust_contrast(arr_img, 0.2) # 调整对比度，相当于a=np.mean(arr_img.numpy(), axis=(0,1));tf.cast((0.2 * (arr_img.numpy() - a) + a), 'uint8')\n",
    "tf.image.adjust_gamma(arr_img, gamma=0.2, gain=1）# 大概相当于tf.cast(255 * (arr_img/255)**0.2, 'uint8')\n",
    "tf.image.random_crop(star, [1000,1000, 3])  # 随机切去[1000,1000]大小的图片，支持批量操作\n",
    "tf.image.random_crop(tf.stack([star, star], 0), [2, 1000, 1000, 3])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.image.flip_left_right(img)  # 左右镜像对称\n",
    "tf.image.rgb_to_grayscale  # 转换为灰度图\n",
    "tf.image.rgb_to_hsv(image)  # image需在[0,1]范围内\n",
    "tf.image.adjust_saturation(image, 3)  # 将image转换为hsv格式后，再将饱和度通道的值乘以3，再转换为rgb格式\n",
    "tf.image.rot90  # 旋转90度\n",
    "tf.image.central_crop(image, central_fraction=0.5) # 剪切，只留下中间50%\n",
    "tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "\n",
       "   ca    thal  target  \n",
       "0   0   fixed       0  \n",
       "1   3  normal       1  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
    "dataframe = pd.read_csv(URL)\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': array([63, 67, 67, 37, 41, 56, 62, 57], dtype=int32),\n",
       " 'sex': array([1, 1, 1, 1, 0, 1, 0, 0], dtype=int32),\n",
       " 'cp': array([1, 4, 4, 3, 2, 2, 4, 4], dtype=int32),\n",
       " 'trestbps': array([145, 160, 120, 130, 130, 120, 140, 120], dtype=int32),\n",
       " 'chol': array([233, 286, 229, 250, 204, 236, 268, 354], dtype=int32),\n",
       " 'fbs': array([1, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'restecg': array([2, 2, 2, 0, 2, 0, 2, 0], dtype=int32),\n",
       " 'thalach': array([150, 108, 129, 187, 172, 178, 160, 163], dtype=int32),\n",
       " 'exang': array([0, 1, 1, 0, 0, 0, 0, 1], dtype=int32),\n",
       " 'oldpeak': array([2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6]),\n",
       " 'slope': array([3, 2, 2, 3, 1, 1, 3, 1], dtype=int32),\n",
       " 'ca': array([0, 3, 2, 0, 0, 0, 2, 0], dtype=int32),\n",
       " 'thal': array([b'fixed', b'normal', b'reversible', b'normal', b'normal',\n",
       "        b'normal', b'normal', b'normal'], dtype=object)}"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataframe.pop('target')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "dataset = dataset.batch(8)\n",
    "one_batch = next(dataset.as_numpy_iterator())[0]\n",
    "one_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.numeric_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "one_age = tf.feature_column.numeric_column('age')\n",
    "feature_layer = layers.DenseFeatures([one_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [2.]], dtype=float32)>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(dict(age=[1,2], ppp=[3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[63.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [37.],\n",
       "       [41.],\n",
       "       [56.],\n",
       "       [62.],\n",
       "       [57.]], dtype=float32)>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.bucketized_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buck_age = tf.feature_column.bucketized_column(one_age, boundaries=[37, 40, 65, 67, 70]) # 输入是numeric_column\n",
    "feature_layer = layers.DenseFeatures(buck_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch) # 第一个区间是开区间，后面的是左闭右开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.categorical_column_with_vocabulary_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.indicator_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### tf.feature_column.embedding_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DenseFeatures only accepts dense tensors, to inspect a categorical column you need to transform that to a indicator column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thal = tf.feature_column.categorical_column_with_vocabulary_list('thal',  ['fixed', 'normal', 'reversible'])\n",
    "thal_one_hot = tf.feature_column.indicator_column(thal)\n",
    "feature_layer = layers.DenseFeatures(thal_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thal_embedding = tf.feature_column.embedding_column(thal, 3)\n",
    "feature_layer = layers.DenseFeatures(thal_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[-0.5390322 , -0.44834587, -0.07046258],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [-0.5288149 ,  0.34261864,  0.02457438],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ],\n",
       "       [ 0.2010104 ,  0.18482254, -0.7510743 ]], dtype=float32)>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer(one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = layers.DenseFeatures([one_age, buck_age, thal_one_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 10), dtype=float32, numpy=\n",
       "array([[63.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [67.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.],\n",
       "       [67.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
       "       [37.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [41.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [56.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [62.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [57.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features(one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_toy(x, y):\n",
    "    x = tf.cast(x, tf.float32)/255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x,y\n",
    "def toy_dataset(n):\n",
    "    (x,y), _ = keras.datasets.mnist.load_data()\n",
    "    idx = np.random.choice(np.arange(x.shape[0]), n, replace=False)\n",
    "    x,y = x[idx], y[idx]\n",
    "    x = tf.expand_dims(x, 3)\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    train_data = train_data.map(process_toy).repeat()\n",
    "    return train_data.shuffle(64).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 函数式API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99513ec62b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=8, kernel_size=[4,4], activation='relu')(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='KerasFunctionAPIModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=8, kernel_size=[4,4], activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3 steps, validate for 3 steps\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 2.1713 - accuracy: 0.2500 - val_loss: 1.9938 - val_accuracy: 0.3125\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7331 - accuracy: 0.4792 - val_loss: 1.7785 - val_accuracy: 0.4896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b1dc048>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = toy_dataset(100)\n",
    "test_data = toy_dataset(100)\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, epochs=2, steps_per_epoch=3, validation_data=test_data, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "为了把Layer在此一并讲清楚，先定制一个Linear层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, name=\"MyDense\"):\n",
    "        super(MyDense, self).__init__(name=name)\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\"w\", shape=[int(input_shape[-1]), self.units],\n",
    "                                 initializer=tf.initializers.glorot_normal(),\n",
    "                                 trainable=True, regularizer=keras.regularizers.l1(0.001),\n",
    "                                 )\n",
    "        self.b = self.add_weight(\"b\", shape=[self.units, ],\n",
    "                                 initializer=tf.initializers.glorot_uniform(),\n",
    "                                 trainable=True,\n",
    "                                 )\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        y = tf.add(tf.matmul(inputs, self.w) , self.b)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, name=\"MyModel\", **kwargs):\n",
    "        super(MyModel, self).__init__(name=name, **kwargs)\n",
    "        self.conv = layers.Conv2D(filters=8, kernel_size=3, activation='relu', name='conv')\n",
    "        self.flatten = layers.Flatten(name='flatten')\n",
    "        self.mydense = MyDense(64, \"mydense\")\n",
    "        self.dense = layers.Dense(32, activation='relu',\n",
    "                                  use_bias=True,\n",
    "                                  bias_initializer=tf.initializers.glorot_uniform(),\n",
    "                                  kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                                  bias_regularizer=keras.regularizers.l2(0.01),\n",
    "                                  name=\"dense\")\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5, name='dropout')\n",
    "        self.y = layers.Dense(10, 'softmax', name='y')\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        conv = self.conv(inputs)\n",
    "        flatten = self.flatten(conv)\n",
    "        mydense = self.mydense(flatten)\n",
    "        dense = self.dense(mydense)\n",
    "        dropout = self.dropout(dense, training=training)\n",
    "        y = self.y(dropout)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(\"HHH\")\n",
    "train_data = toy_dataset(100)\n",
    "a = next(iter(train_data))[0]\n",
    "model(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 22:17:23.362029 4642928064 save_impl.py:77] Skipping full serialization of Keras model <__main__.MyModel object at 0x141f03cc0>, because its inputs are not defined.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"test/minimodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HHH\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv (Conv2D)                multiple                  80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "mydense (MyDense)            multiple                  346176    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "y (Dense)                    multiple                  330       \n",
      "=================================================================\n",
      "Total params: 348,666\n",
      "Trainable params: 348,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=2761, shape=(), dtype=float32, numpy=5.4401956>,\n",
       " <tf.Tensor: id=2769, shape=(), dtype=float32, numpy=0.4249903>,\n",
       " <tf.Tensor: id=2777, shape=(), dtype=float32, numpy=0.010632831>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=2785, shape=(), dtype=float32, numpy=5.4401956>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('mydense').losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5408, 64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('mydense').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关于定制的层**  \n",
    "* `__init__`：可以执行与输入无关的初始化；\n",
    "* `build`：按照输入张量的shape初始化权重，也可以进行其他的初始化；\n",
    "* `call`：进行正向计算。\n",
    "\n",
    "\n",
    "* 第一次调用`__call__`时会首先调用`build`，建立权重；之后调用`call`进行运算；  \n",
    "* `call`不会自动调用`build`，因此在手动调用`call`之前必须保证权重张量已经存在了；\n",
    "* 用`build`而不是`__init__`初始化权重是好处是：可以不必过早的指定输入数据的维度，而是在需要计算的时候指定输入数据，再根据输入数据确定权重的shape，初始化权重。也就是可以直到调用`model.fit`方法进行训练时，才根据输入数据的shape初始化权重。\n",
    "\n",
    "**关于Layer的help信息如下，help(tf.keras.layers.Layer)：**\n",
    "* `__init__()`: Save configuration in member variables\n",
    "* `build()`: Called once from `__call__`, when we know the shapes of inputs and `dtype`. Should have the calls to `add_weight()`, and then call the super's `build()` (which sets `self.built = True`, which is nice in case the user wants to call `build()` manually before the first `__call__`).\n",
    " * `call()`: Called in `__call__` after making sure `build()` has been called once. Should actually perform the logic of applying the layer to the input tensors (which should be passed in as the first argument)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tf.keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None)\n",
    "```\n",
    "* units: 输出神经元个数\n",
    "* activation：激活函数\n",
    "* use_bias: Boolean, whether the layer uses a bias vector\n",
    "* kernel_initializer: Initializer for the `kernel` weights matrix.\n",
    "* bias_initializer: Initializer for the bias vector.\n",
    "* kernel_regularizer: Regularizer function applied to the `kernel` weights matrix.\n",
    "* bias_regularizer: Regularizer function applied to the bias vector.\n",
    "* `Dense` implements the operation: `output = activation(dot(input, kernel) + bias)`；因此如果是输入没有经过Flatten，也就是多个维度，那么输出本层相当于进行了一次$1\\times1$的卷积；实际上kernel就是一个两个维度的矩阵，第一个维度由输入决定，第二个维度units决定；输入和输出的差别就是最后一个维度不同：$input.shape[-1] \\to units$\n",
    "* input一行是一个样本，那么kernel的行数就是输入神经元的个数，kernel的列数就是输出神经元的个数。\n",
    "* Input shape: (batch_size, input_dim)\n",
    "* Output shape: (batch_size, units)\n",
    "* `__call__(self, inputs, *args, **kwargs)`方法：会调用`call`方法，返回输出张量\n",
    "* 如果本层在第一层，可以通过参数`input_dim=512`指定输入的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',input_length=None)\n",
    "```\n",
    "* `input_dim`是单词表的长度+1，`output_dim`是嵌入向量的长度，`input_length`：仅截取每个样本的前`input_length`个词\n",
    "* 输入是一个batch的数据，其中每个样本的每个单词是其在单词表中的下标；输出增加了一个维度，就是单词用嵌入向量表示了\n",
    "* `.get_weights()`返回该层的参数，`shape=[input_dim, output_dim]`，每一行代表了一个单词的嵌入向量（跳字模型的中心词向量）\n",
    "* input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect `Flatten`, then `Dense` layers upstream (without it, the shape of the dense outputs cannot be computed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 10, 3])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = layers.Embedding(10, 3, input_length=8)\n",
    "x = np.random.randint(8, size=[20, 10])\n",
    "embed(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "layers.SimpleRNN(units, return_sequences)\n",
    "```\n",
    "* 零时间步的初始状态为全0向量，之后的每一步输出是下一个时间步的状态；\n",
    "* rnn的每一个时间步的输入shape是`[batch_size,timesteps, input_features]`\n",
    "* 输出的shape是`[batch_size, output_features]`，`output_features`就是参数中的units\n",
    "* 如果参数设置为`return_sequences=True`，则输出的shape为`[batch_size, timesteps, output_features]`，也就是每个时间步都输出，如果作为中间层，则应该设置为`return_sequences=True`\n",
    "* `self.build(input_shape=[])`，初始化权重，第一个权重的第一个维度是`input_shape[-1]`，第二个维度是输出的维度units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 8, 5])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = layers.SimpleRNN(5, return_sequences=True)\n",
    "x = tf.random.normal([6, 8, 3])\n",
    "rnn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "(5, 5)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "for i in rnn.trainable_variables:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3142, shape=(5,), dtype=float32, numpy=\n",
       "array([-0.8712967 , -0.09798537, -0.9270312 , -0.39548007,  0.7941837 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是第一个样本，第二个时间步的计算过程，数值稍微有点出入，且不深究\n",
    "a = np.dot(x[0,1], rnn.get_weights()[0])\n",
    "b = np.dot(rnn(x)[0,0], rnn.get_weights()[1])\n",
    "r = tf.nn.tanh(a+b+rnn.get_weights()[2])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3282, shape=(5,), dtype=float32, numpy=\n",
       "array([-0.8712967 , -0.09798539, -0.9270312 , -0.39548007,  0.7941837 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(x)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stateful=True: 上一批次的第i个样本的输出状态（包括输出和“传送带”），作为下一个批次第i个样本的起始状态（包括隐藏状态和“传送带”）。这也导致了当设置stateful=True时，batch size必须是固定的，如果需要改变batch size的大小，可以考虑checkpoint保存权重，重新建立模型，再加载权重。\n",
    "\n",
    "\n",
    "If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors:\n",
    "- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\n",
    "- If using the functional API, specify the batch size by passing a `batch_shape` argument to your Input layer.\n",
    "- 下面的测试说明，如果是用subclass则不需要任何改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.reset_states() 或者lstm.reset_states() 可以将状态设置为全0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestStateful(keras.Model):\n",
    "    def __init__(self, name='TestStateful', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.embed = layers.Embedding(10, 3)\n",
    "        self.lstm = layers.LSTM(4, return_sequences=True, stateful=True)\n",
    "        #self.lstm = layers.LSTM(4, return_sequences=True, stateful=False)\n",
    "    def call(self, inputs, training=False):\n",
    "        embed = self.embed(inputs)\n",
    "        lstm = self.lstm(embed)\n",
    "        return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 10, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TestStateful()\n",
    "x = np.random.randint(8, size=[20, 10])\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 16])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(model.lstm.weights[:2], axis=0).shape  # 实际上这就是4个权重变量，axis=0就是把输入和隐藏状态的concate 做点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.lstm.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(model(x)[:,-1,:] == model.lstm.states[0])  # states的第一个值就是隐藏状态，第二个值应该是“传送带”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到有两个状态，应该一个是最后一个输出，另一个是“传送带”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = layers.LSTM(4, return_state=True, return_sequences=True, stateful=True)\n",
    "x = tf.random.normal([20, 10, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(lstm(x)[1] == lstm.states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### layers.Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "双向RNN利用的RNN的顺序敏感性：它包含两个普通RNN，每个RNN分别沿一个方向对输入序列进行处理（时间正序和时间逆序），然后将它们的表示合并到一起（concat）。通过沿这两个方向处理序列，双向RNN能捕捉到可能被单向RNN忽略的模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### layers.Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "layers.Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None)\n",
    "```\n",
    "* 一维卷积神经网络用于文本和序列\n",
    "* 输入的形状是(batch_size, timesteps, features)，在时间轴上做卷积；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.SeparableConv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 深度可分离卷积层：每个层分别进行卷积操作，卷积结果concatenate到一起形成多个层，再用pointwise（$1\\times 1$）卷积，将各个通道混合。\n",
    "* 这么做相当于是把空间特征学习和通道特征学习分开，如果你假设输入中的空间位置高度相关，但不同的通道之间相互独立，那么这么做是很有意义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 5, 5, 16])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.random.normal([8, 10, 10, 3])\n",
    "test = layers.SeparableConv2D(filters=16, kernel_size=4, strides=2, padding='same')\n",
    "test(tmp).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### layers.MaxPooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "layers.MaxPooling(pool_size=2, strides=None, padding='valid', data_format='channels_last')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### layers.GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "layers.GlobalAveragePooling1D(data_format='channels_last')\n",
    "```\n",
    "* 默认输入为`[batch,timesteps,features]`，在`timesteps`维度上做池化；形象点就是在这一批次的词中，在每一个词向量的同一维度上做池化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers.Conv2DTranspose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原理参考[这篇文献](https://arxiv.org/pdf/1603.07285.pdf)，在第20页，4.1节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 4, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.random.normal([1, 4, 4, 1])\n",
    "test = layers.Conv2DTranspose(2, 3, strides=1, padding='same')\n",
    "test(tmp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.variables[0].shape  # 就是想说明实际上参数还是kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL和keras对于图片的坐标系统都是左上角为（0，0），但是keras的坐标点是（y_height, x_width)，而PIL的坐标点是（x_width, y_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 2304)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kimg = tf.keras.preprocessing.image.load_img('data/TheStarryNight.jpg')\n",
    "kimg.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 2304)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kimg.width, kimg.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([236., 179.,  46.], dtype=float32)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.img_to_array(kimg)[100, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 2304)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pimg = Image.open(\"data/TheStarryNight.jpg\")\n",
    "pimg.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 2304)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pimg.width,pimg.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 179, 46)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pimg.getpixel((3000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([236, 179,  46], dtype=uint8)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pimg)[100, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "newimg = Image.new (\"RGB\", (300, 300), (255, 0, 0))\n",
    "draw = ImageDraw.Draw(newimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.chord((10, 50, 40, 100), 0, 360, fill='green')\n",
    "draw.chord((150,150, 200,200), 0, 360)\n",
    "draw.rectangle((150, 150, 200, 200))\n",
    "draw.text((150, 150), \"HelloWorld\", fill='blue')\n",
    "#newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(imgs.flow_from_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "fnames = ['/Users/user/.keras/datasets/flower_photos/roses', '/Users/user/.keras/datasets/flower_photos/sunflowers']\n",
    "imgs = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, \n",
    "                                          rotation_range=40, #随机旋转角度\n",
    "                                          width_shift_range=0.2, height_shift_range=0.2, # 水平或垂直方向平移的距离（相对于总宽度或总高度的比例）\n",
    "                                          shear_range=0.2, # 随机错切变换的角度\n",
    "                                          zoom_range=0.2, # 图像随机缩放的范围\n",
    "                                          horizontal_flip=True, #随机将一半的图片水平翻转\n",
    "                                          fill_mode='nearest')\n",
    "imgs_generator = imgs.flow_from_directory('/Users/user/.keras/datasets/flower_photos', target_size=(150, 150), \n",
    "                                          batch_size=20, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imgs_generator.next()\n",
    "#plt.imshow(a[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['daisy/2019064575_7656b9340f_m.jpg',\n",
       " 'daisy/3415180846_d7b5cced14_m.jpg',\n",
       " 'daisy/4144275653_7c02d47d9b.jpg',\n",
       " 'sunflowers/8481979626_98c9f88848_n.jpg',\n",
       " 'sunflowers/9555824387_32b151e9b0_m.jpg',\n",
       " 'sunflowers/9555827829_74e6f60f1d_m.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = keras.preprocessing.image.ImageDataGenerator(validation_split=0.25)\n",
    "d_train = d.flow_from_directory('data/flowers', subset='training', shuffle=True)\n",
    "d_train.filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ', split=' ')\n",
    "```\n",
    "* `num_words`：只有最常出现的`num_words`个词会被保留\n",
    "* `filters`：会被过滤掉的，实际上可以认为被替换成`split`指定的分割字符串\n",
    "* `split`：指定分割文本用的字符串，默认是空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = prep.text.Tokenizer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"if you want to sound like a native speaker , you must be willing to practice saying the want to to sound native\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([x, ])  # 参数字符串组成的list，得到按词频排序的单词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(['you you you you you']) # 接着训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'you',\n",
       " 2: 'to',\n",
       " 3: 'want',\n",
       " 4: 'sound',\n",
       " 5: 'native',\n",
       " 6: 'if',\n",
       " 7: 'like',\n",
       " 8: 'a',\n",
       " 9: 'speaker',\n",
       " 10: 'must',\n",
       " 11: 'be',\n",
       " 12: 'willing',\n",
       " 13: 'practice',\n",
       " 14: 'saying',\n",
       " 15: 'the'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word  # 下标-单词 组成的字典，包括所有单词，词频大的下标小；.word_index与之相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenizer.word_counts # [(单词，频率), (...), ...]，是一个OrderedDict，按训练样本中单词出现的顺序排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 2], [2, 3, 1]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"you are want to a\", \"a to want are you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you want to']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[1,3,2, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_matrix(['you are wang to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'are', 'my', 'best', 'friend', 'you']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.text.text_to_word_sequence('you are my best friend you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.preprocessing.sequence.TimeseriesGenerator(data, targets, length, sampling_rate=1, stride=1, start_index=0, end_index=None, shuffle=False, reverse=False, batch_size=128)\n",
    "```\n",
    "* `data`：是可索引的生成器（例如元组，列表或numpy数组），第0个轴是时间维度\n",
    "* `targets`：对应的data时间步的目标值，第0个维度与data的时间维度长度相同\n",
    "* `length`：每个样本有考虑多少个时间步，或者说当sampling_rate=1时，生成的结果中一个targets值对应多少个data值\n",
    "* `sampling_rate`：时间步的采样周期，例如当`length=10, sampleing_rate=2`时，每2个时间步取一次，结果就是每个目标值只对应5个时间步，但是跨越了10个时间步\n",
    "* `stride`：目标值的采样周期\n",
    "* `start_index,end_index`：data和targets的下标在`[start_index, end_index]`之间的时间步才会被用到\n",
    "* `shuffle`：是否打乱样本\n",
    "* `reverse`：是否按时间步的倒序输出\n",
    "* `batch_size`：每个批次的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([chr(i) for i in range(97, 117)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[i] for i in range(50)])\n",
    "targets = np.random.normal(size=[50, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = prep.sequence.TimeseriesGenerator(data, targets, length=10, sampling_rate=2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.],\n",
       "         [2.],\n",
       "         [4.],\n",
       "         [6.],\n",
       "         [8.]],\n",
       " \n",
       "        [[1.],\n",
       "         [3.],\n",
       "         [5.],\n",
       "         [7.],\n",
       "         [9.]]]), array([[-0.9120223 , -0.44903765, -0.45272137],\n",
       "        [-1.5934117 ,  0.01738436,  0.91008626]]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9120223 , -0.44903765, -0.45272137])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "prep.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
    "```\n",
    "* sequences：列表的列表，每一个元素是一个序列\n",
    "* maxlen：默认是所有序列中最长的长度\n",
    "* value：浮点数，用来补齐的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [0, 3],\n",
       "       [4, 5]], dtype=int32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,3], [3,], [4,5]]\n",
    "prep.sequence.pad_sequences(x, maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32801, shape=(1, 20), dtype=int64, numpy=array([[0, 0, 0, 0, 2, 1, 0, 2, 2, 3, 3, 0, 1, 4, 2, 2, 3, 3, 3, 0]])>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.categorical([tf.nn.softmax(tf.random.normal([5]))], 20)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfds.list_builders() # 可用数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "# as_supervised=True 返回数据+标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tfds.features.text.Tokenizer(alphanum_only=True, reserved_tokens=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"one one two two th,ree one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th,ree', 'one']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer(reserved_tokens=['th,ree',])\n",
    "tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', ' ', 'one', ' ', 'two', ' ', 'two', ' ', 'th', ',', 'ree', ' ', 'one']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer(alphanum_only=False)\n",
    "tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th', 'ree', 'one']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tfds.features.text.TokenTextEncoder(tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th', 'ree', 'one']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th', 'ree', 'one']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.SubwordTextEncoder.build_from_corpus(['one two aa aaa ', 'you are one two aa aa bbb,bb'], target_vocab_size=2**15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa_', 'two_', 'one_', 'you_', 'bbb', 'bb', 'are_', 'aaa_']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 1, 93, 41, 125]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode('aa aaa aa T t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 106, 106, 106, 41, 46, 46, 41, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode('aaa aaa %% two ') # 为啥第二个aaa_被分割成字母了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one aa one #'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder.decode([3, 1, 0, 3]) # ValueError，0只能在最后\n",
    "encoder.decode([3, 1, 3, 44, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 41, 5, 6]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode('bb bbbbb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
