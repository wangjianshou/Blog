{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TensorFlow2学习笔记\" data-toc-modified-id=\"TensorFlow2学习笔记-0\">TensorFlow2学习笔记</a></span></li><li><span><a href=\"#Stateful-Container\" data-toc-modified-id=\"Stateful-Container-1\">Stateful Container</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Trackable\" data-toc-modified-id=\"Trackable-1.0.1\">Trackable</a></span></li><li><span><a href=\"#AutoTrackable\" data-toc-modified-id=\"AutoTrackable-1.0.2\">AutoTrackable</a></span></li><li><span><a href=\"#可以被保存的对象\" data-toc-modified-id=\"可以被保存的对象-1.0.3\">可以被保存的对象</a></span></li><li><span><a href=\"#Restore-on-Creation\" data-toc-modified-id=\"Restore-on-Creation-1.0.4\">Restore-on-Creation</a></span></li><li><span><a href=\"#tf.Module\" data-toc-modified-id=\"tf.Module-1.0.5\">tf.Module</a></span></li></ul></li></ul></li><li><span><a href=\"#tf.function\" data-toc-modified-id=\"tf.function-2\">tf.function</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#基本特征\" data-toc-modified-id=\"基本特征-2.0.1\">基本特征</a></span></li><li><span><a href=\"#运行过程\" data-toc-modified-id=\"运行过程-2.0.2\">运行过程</a></span></li><li><span><a href=\"#实例\" data-toc-modified-id=\"实例-2.0.3\">实例</a></span></li><li><span><a href=\"#可变类型作为函数的参数\" data-toc-modified-id=\"可变类型作为函数的参数-2.0.4\">可变类型作为函数的参数</a></span></li><li><span><a href=\"#自定义类的序列化\" data-toc-modified-id=\"自定义类的序列化-2.0.5\">自定义类的序列化</a></span></li></ul></li></ul></li><li><span><a href=\"#tf.data\" data-toc-modified-id=\"tf.data-3\">tf.data</a></span></li><li><span><a href=\"#API\" data-toc-modified-id=\"API-4\">API</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf.TensorArray\" data-toc-modified-id=\"tf.TensorArray-4.1\">tf.TensorArray</a></span></li><li><span><a href=\"#tf.save_model\" data-toc-modified-id=\"tf.save_model-4.2\">tf.save_model</a></span></li><li><span><a href=\"#tf.train\" data-toc-modified-id=\"tf.train-4.3\">tf.train</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#tf.train.Checkpoint\" data-toc-modified-id=\"tf.train.Checkpoint-4.3.0.1\">tf.train.Checkpoint</a></span></li></ul></li></ul></li><li><span><a href=\"#tf.initializer\" data-toc-modified-id=\"tf.initializer-4.4\">tf.initializer</a></span></li><li><span><a href=\"#tf.linalg\" data-toc-modified-id=\"tf.linalg-4.5\">tf.linalg</a></span></li><li><span><a href=\"#tf.math\" data-toc-modified-id=\"tf.math-4.6\">tf.math</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf.GradientTape\" data-toc-modified-id=\"tf.GradientTape-4.6.1\">tf.GradientTape</a></span></li><li><span><a href=\"#tf.losses\" data-toc-modified-id=\"tf.losses-4.6.2\">tf.losses</a></span></li><li><span><a href=\"#tf.metrics\" data-toc-modified-id=\"tf.metrics-4.6.3\">tf.metrics</a></span></li></ul></li><li><span><a href=\"#tf.optimizer\" data-toc-modified-id=\"tf.optimizer-4.7\">tf.optimizer</a></span></li><li><span><a href=\"#tf.nn\" data-toc-modified-id=\"tf.nn-4.8\">tf.nn</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#tf.nn.top_k\" data-toc-modified-id=\"tf.nn.top_k-4.8.0.1\">tf.nn.top_k</a></span></li><li><span><a href=\"#tf.nn.moment\" data-toc-modified-id=\"tf.nn.moment-4.8.0.2\">tf.nn.moment</a></span></li><li><span><a href=\"#tf.nn.batch_normalization\" data-toc-modified-id=\"tf.nn.batch_normalization-4.8.0.3\">tf.nn.batch_normalization</a></span></li><li><span><a href=\"#tf.keras.layers.BatchNormalization\" data-toc-modified-id=\"tf.keras.layers.BatchNormalization-4.8.0.4\">tf.keras.layers.BatchNormalization</a></span></li><li><span><a href=\"#tf.nn.softmax\" data-toc-modified-id=\"tf.nn.softmax-4.8.0.5\">tf.nn.softmax</a></span></li><li><span><a href=\"#tf.nn.softmax_cross_entropy_with_logits\" data-toc-modified-id=\"tf.nn.softmax_cross_entropy_with_logits-4.8.0.6\">tf.nn.softmax_cross_entropy_with_logits</a></span></li><li><span><a href=\"#tf.nn.conv2d\" data-toc-modified-id=\"tf.nn.conv2d-4.8.0.7\">tf.nn.conv2d</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Keras\" data-toc-modified-id=\"Keras-5\">Keras</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#toy-dataset\" data-toc-modified-id=\"toy-dataset-5.0.1\">toy dataset</a></span></li></ul></li><li><span><a href=\"#函数式API\" data-toc-modified-id=\"函数式API-5.1\">函数式API</a></span></li><li><span><a href=\"#Sequential\" data-toc-modified-id=\"Sequential-5.2\">Sequential</a></span></li><li><span><a href=\"#subclass\" data-toc-modified-id=\"subclass-5.3\">subclass</a></span></li><li><span><a href=\"#layers\" data-toc-modified-id=\"layers-5.4\">layers</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#layers.Dense\" data-toc-modified-id=\"layers.Dense-5.4.0.1\">layers.Dense</a></span></li><li><span><a href=\"#layers.Embedding\" data-toc-modified-id=\"layers.Embedding-5.4.0.2\">layers.Embedding</a></span></li><li><span><a href=\"#layers.SimpleRNN\" data-toc-modified-id=\"layers.SimpleRNN-5.4.0.3\">layers.SimpleRNN</a></span></li><li><span><a href=\"#layers.LSTM\" data-toc-modified-id=\"layers.LSTM-5.4.0.4\">layers.LSTM</a></span></li><li><span><a href=\"#layers.GRU\" data-toc-modified-id=\"layers.GRU-5.4.0.5\">layers.GRU</a></span></li><li><span><a href=\"#layers.Bidirectional\" data-toc-modified-id=\"layers.Bidirectional-5.4.0.6\">layers.Bidirectional</a></span></li><li><span><a href=\"#layers.Conv1D\" data-toc-modified-id=\"layers.Conv1D-5.4.0.7\">layers.Conv1D</a></span></li><li><span><a href=\"#layers.MaxPooling\" data-toc-modified-id=\"layers.MaxPooling-5.4.0.8\">layers.MaxPooling</a></span></li><li><span><a href=\"#layers.GlobalAveragePooling1D\" data-toc-modified-id=\"layers.GlobalAveragePooling1D-5.4.0.9\">layers.GlobalAveragePooling1D</a></span></li><li><span><a href=\"#layers.Conv2DTranspose\" data-toc-modified-id=\"layers.Conv2DTranspose-5.4.0.10\">layers.Conv2DTranspose</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#keras.preprocessing\" data-toc-modified-id=\"keras.preprocessing-6\">keras.preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#text\" data-toc-modified-id=\"text-6.1\">text</a></span></li><li><span><a href=\"#sequence\" data-toc-modified-id=\"sequence-6.2\">sequence</a></span></li><li><span><a href=\"#pad_sequences\" data-toc-modified-id=\"pad_sequences-6.3\">pad_sequences</a></span></li></ul></li><li><span><a href=\"#tensorflow_datasets\" data-toc-modified-id=\"tensorflow_datasets-7\">tensorflow_datasets</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# TensorFlow2学习笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "本笔记参考了下面的书籍、文献、博客或者官方说明：\n",
    "* TensorFlow2官方文档：https://tensorflow.google.cn/\n",
    "* 简单粗暴TensorFlow 2：https://github.com/snowkylin/tensorflow-handbook\n",
    "* TensorFlow 2.0 学习笔记：https://zhuanlan.zhihu.com/p/74441082\n",
    "\n",
    "未注明出处的代码示例，`大概`就是我自己编的，`大概`的意思就是也有极小的概率是忘记注明了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets  as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing as prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true,
    "toc-hr-collapsed": false
   },
   "source": [
    "# Stateful Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### Trackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.training.tracking.base import Trackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1412af358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Trackable()\n",
    "y = Trackable()\n",
    "x._track_trackable(y, 'ccc') # x引用y，并且叫该引用命名为'ccc'，或者说x依赖y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc') is y  # 返回名称为'ccc'的引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1412af358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1412af358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.base.Trackable at 0x1412af358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "可以看到删除y之后，不影响x对其引用。因此只要根节点x没有被回收，那么x所依赖的对象就不会被回收。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "### AutoTrackable\n",
    "AutoTrackabke类继承Trackable类，通过`__setattr__`和`__getattr__`属性拦截访问和设置新属性（访问和建立依赖关系）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.training.tracking.tracking import AutoTrackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = AutoTrackable()\n",
    "y = AutoTrackable()\n",
    "x.ccc = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._lookup_dependency('ccc') is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v = tf.Variable([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x.vvv = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrackableReference(name='ccc', ref=<tensorflow.python.training.tracking.tracking.AutoTrackable object at 0x1412afc88>),\n",
       " TrackableReference(name='vvv', ref=<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._unconditional_checkpoint_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### 可以被保存的对象\n",
    "**tf.Variable和MutableHashTable**  \n",
    "tf.Variable类和MutableHashTable类是可以被保存的对象(用于tf.train.Checkpoint)，这两个类继承自Trackable类，并且覆盖了`_gather_saveables_for_checkpoint`方法，用tf.train.Checkpoint来保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.lookup_ops import MutableHashTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._gather_saveables_for_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VARIABLE_VALUE': <tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.vvv._gather_saveables_for_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "实际上，Checkpoint使用了ObjectGraphView类，遍历整个DAG节点，并调用`_gather_saveables_for_checkpoint`方法类收集可以被保存的对象以及它们的依赖关系并存储。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### Restore-on-Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'test/Variable:0' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def assign(self, init=tf.constant([1., 2., 3.]), name=None):\n",
    "        with self.name_scope:\n",
    "          self.w = tf.Variable(init)\n",
    "    def operate(self, value):\n",
    "        self.w.assign_add(value)\n",
    "\n",
    "m = MyModule(name='test')\n",
    "m.assign()\n",
    "m.operate([1., 1., 1.])\n",
    "m.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ckpt.save.test-1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(module=m)\n",
    "ckpt.save('data/ckpt.save.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "module = MyModule(name='test')\n",
    "try:\n",
    "    module.w\n",
    "except AttributeError as e:\n",
    "    print(\"w doesn't exist.\")\n",
    "else:\n",
    "    print(\"w already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "由于没用调用assign方法，可以看到w属性是不存在的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1412db518>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(module=module)\n",
    "ckpt.restore(tf.train.latest_checkpoint('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    module.w\n",
    "except AttributeError as e:\n",
    "    print(\"w doesn't exist.\")\n",
    "else:\n",
    "    print(\"w already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "可以看到由于w属性没有建立，因此restore之后，w依然是不存在的。但是当调用assign方法建立w属性的时候，restore就会起作用了，可以看到结果是restore得到的结果，并不是assign的参数所指定的`tf.constant([1., 1., 1.])`。  \n",
    "\n",
    "**Restore-on-Creation机制就是在权重没有建立时，暂时不加载checkpoint保存的权重，一旦建立，则立即加载。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'test/Variable:0' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.assign(tf.constant([1., 1., 1.]))\n",
    "module.w  # so you see..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### tf.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "`tf.variables`：收集所有变量；  \n",
    "`tf.trainable_variables`：收集所有可训练的变量；  \n",
    "`tf.submodules`：收集所有子模块。\n",
    "\n",
    "> You can enter the name scope explicitly using `with self.name_scope:` or you can annotate methods(apart from `__init__`) with `@tf.Module.with_name_scope`.\n",
    "\n",
    "注意使用`@tf.Module.with_name_scope`或者`with self.name_scope`，必须在`__init__`中调用`super().__init__`，以此来调用`tf.Module`类的构建函数`__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=98, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[0.       , 1.1897867, 0.       ],\n",
       "       [0.       , 1.1897867, 0.       ],\n",
       "       [0.       , 1.1897867, 0.       ],\n",
       "       [0.       , 1.1897867, 0.       ],\n",
       "       [0.       , 1.1897867, 0.       ],\n",
       "       [0.       , 1.1897867, 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dense(tf.Module):\n",
    "  def __init__(self, input_features, output_features, name=None):\n",
    "    super(Dense, self).__init__(name=name)\n",
    "    with self.name_scope:\n",
    "      self.w = tf.Variable(tf.random.normal([input_features, output_features], name='w'))\n",
    "      self.b = tf.Variable(tf.zeros([output_features,]), name='b')\n",
    "  @tf.Module.with_name_scope\n",
    "  def __call__(self, x):\n",
    "    self.test = tf.Variable([2.,3.], name='ahaha')\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)\n",
    "\n",
    "d = Dense(input_features=5, output_features=3)\n",
    "d(tf.ones([6, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense/b:0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.variables[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense/'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.name_scope.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense/ahaha:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "# tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### 基本特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "* tf.function 装饰器返回的是def_function.Function对象；\n",
    "* Function对象是由一个个的ConcreteFunction函数组成；ConcreteFunction对象是由包含了FunctionGraph和structured_input_signature；\n",
    "* FunctionGraph是tf.Graph的子类，strucured_input_signature是函数签名；\n",
    "* 如果传入的参数是一个python值，则会对每一个遇到的pyhon值创建一个ConcreteFunction，实际上python值会成为Graph的一个固定的值，如果创建ConcreteFunction时，参数是一个python的引用，则此时引用的值就被固定在Graph中；\n",
    "* 这也说明，如果是参数是可变了python值，那么，在函数中就不能运行原处改变的操作，因为该值已经被固定在Graph中了；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### 运行过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "1. 运行函数的每一行代码，代码分为两类：\n",
    "  * 纯python代码；\n",
    "  * tensorflow代码，如`tf.add`，以及可以转换为计算节点的python代码；  \n",
    "运行的结果就是：纯python代码会与运行普通的python代码相同，tensorflow代码与可以转换为计算节点的python代码会构建为计算图。\n",
    "2. 运行计算图一次\n",
    "3. 基于函数的名字和输入的函数参数类型生成一个哈希值，并将计算的计算图缓存到一个哈希表中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "**AutoGraph与if，while循环：**  \n",
    "* for：如果iterable是张量，则转换；\n",
    "* while：如果while条件是张量，则转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add(x, y):\n",
    "    return tf.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=119, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-0.7604835 ,  0.229419  , -1.1680298 ],\n",
       "       [ 0.67251945,  0.20211482, -0.6708729 ]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(tf.random.normal((2, 3)), tf.random.normal((3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=138, shape=(2, 6), dtype=float32, numpy=\n",
       "array([[ 1.8798205 , -0.8328358 , -1.3877598 ,  0.65484244, -1.9559011 ,\n",
       "        -1.1521152 ],\n",
       "       [ 0.6196594 , -0.18621588, -1.2692846 ,  0.00383502, -1.1147664 ,\n",
       "         1.3494377 ]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(tf.random.normal((2, 6)), tf.random.normal((6,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.eager.function.ConcreteFunction at 0x141da6f60>,\n",
       " <tensorflow.python.eager.function.ConcreteFunction at 0x141dc9d68>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=164, shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(3,5);add(6,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2, 6), dtype=tf.float32, name='x'),\n",
       "  TensorSpec(shape=(6,), dtype=tf.float32, name='y')),\n",
       " {})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[2].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 9), {})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[3].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=165, shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[3]()  # 参数是python值所对应的ConcreteFunction函数不需要传入参数了，因为参数值已经固定在里面了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.eager.function.ConcreteFunction at 0x141da6f60>,\n",
       " <tensorflow.python.eager.function.ConcreteFunction at 0x141b6c748>,\n",
       " <tensorflow.python.eager.function.ConcreteFunction at 0x141dc9d68>,\n",
       " <tensorflow.python.eager.function.ConcreteFunction at 0x141e146a0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2, 3), dtype=tf.float32, name='x'),\n",
       "  TensorSpec(shape=(3,), dtype=tf.float32, name='y')),\n",
       " {})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = add._list_all_concrete_functions_for_serialization()[0].structured_input_signature\n",
    "sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "`.get_concrete_function`获取ConcreteFunction，奇怪的是两种方式获得ConcreteFunction并不相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = add.get_concrete_function(tf.TensorSpec(shape=[2,6], dtype=tf.float32), tf.TensorSpec(shape=[6,], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.function.ConcreteFunction at 0x141e30ba8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.function.ConcreteFunction at 0x141da6f60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add._list_all_concrete_functions_for_serialization()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "tf.function只允许在第一次调用函数时，创建tf.Variable；因此典型用法应当是在`__init__`方法中设置权重为`None`，然后在`build`方法中加以判断，如果权重为`None`，则初始化权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v = None\n",
    "\n",
    "def f(x):\n",
    "    global v\n",
    "    if v is None:\n",
    "      v = tf.Variable(x)\n",
    "    return v\n",
    "f = tf.function(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0221 22:16:47.158362 4642928064 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=233, shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(tf.constant([2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=241, shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(tf.constant([2., 3.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "当我把v重新设置成None时，导致再次调用函数f时会试图创建variable，因此抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError when create variable non-first call\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v = None\n",
    "    f(tf.constant([1.,2, 3.]))\n",
    "except ValueError:\n",
    "    print(\"ValueError when create variable non-first call\")\n",
    "else:\n",
    "    print(\"isn't ok?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "正确的用法应当是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name, units=10):\n",
    "        super(MyModule, self).__init__(name=name)\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.units = units\n",
    "    @tf.Module.with_name_scope\n",
    "    def build(self, input_shape):\n",
    "        if self.w is None:\n",
    "            self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]))\n",
    "        if self.b is None:\n",
    "            self.b = tf.Variable(tf.random.normal([self.units, ]))\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.w) + self.b\n",
    "    @tf.function\n",
    "    def __call__(self, input):\n",
    "        self.build(input.shape)\n",
    "        return self.call(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyModule('testModule')\n",
    "input = tf.random.normal([5,3])\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(5, 3), dtype=tf.float32, name='input'),), {})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.__call__._list_all_concrete_functions_for_serialization()[0].structured_input_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "如果注释掉`build`方法中的两个`if`判断语句，导致`ValueError when create variable non-first call`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### 可变类型作为函数的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    print(x)\n",
    "    # 这一行会导致错误，也就是说参数是可变类型的原处操作会导致运行错误\n",
    "    # x.append(100) \n",
    "    return x[-1] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = [1.,2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=360, shape=(), dtype=float32, numpy=102.0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=361, shape=(), dtype=float32, numpy=102.0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.get_concrete_function(x)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([1.0, 2.0],), {})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()[0].structured_input_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "可以看到上面的例子说明：python的可变类型作为参数时，除了不能用原处操作的方法外，其他的和python值作为参数时是相同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "下面这个例子来自于TensorFlow 2官方文档："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'add:0' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [] \n",
    "@tf.function \n",
    "def f(x): \n",
    "  for i in x: \n",
    "    l.append(i + 1)    # Caution! Will only happen once when tracing \n",
    "f(tf.constant([1, 2, 3])) \n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.function.ConcreteFunction at 0x141f0a898>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "@tf.function\n",
    "def f(a):\n",
    "    for i in range(a):\n",
    "        l.append(0)  # 只会在构建计算图时运行一次\n",
    "        tf.print(a)  # 会成为计算图的一个计算节点，每次调用都会运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)  # 第二次调用并不会改变list的值，因为第二次只会运行计算图\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### 自定义类的序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, age):\n",
    "        self.age = age\n",
    "\n",
    "@tf.function\n",
    "def f(year, p):\n",
    "    print(year)\n",
    "    return p.age + year\n",
    "\n",
    "p = Person(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=465, shape=(), dtype=int32, numpy=101>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=470, shape=(), dtype=int32, numpy=102>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=471, shape=(), dtype=int32, numpy=102>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, <tensorflow.python.framework.func_graph.UnknownArgument at 0x1420fefd0>),\n",
       " {})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.get_concrete_function(2,p).structured_input_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "可能是由于Person类并没有序列化，因此导致`_list_all_concrete_functions_for_serialization`并不能获取`ConcreteFunction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f._list_all_concrete_functions_for_serialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([5, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n",
      "TensorShape([None, 10])\n",
      "TensorShape([4, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=535, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def concat_with_padding():\n",
    "    x = tf.zeros([5, 10])\n",
    "    tf.print(x.shape)\n",
    "    x = x[:4]\n",
    "    tf.print(x.shape)\n",
    "    for i in tf.range(4):\n",
    "        x = tf.concat([x[:i], tf.ones([1, 10])], axis=0) # 循环时张量形状不能改变\n",
    "        tf.print(x.shape)\n",
    "        x.set_shape([4, 10])\n",
    "        tf.print(x.shape)\n",
    "    return x\n",
    "concat_with_padding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "# tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* `drop_remainder=True`：如果最后一个批次样本数不足，则弃之不用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=550, shape=(), dtype=int64, numpy=1>,\n",
       " <tf.Tensor: id=551, shape=(), dtype=int64, numpy=2>,\n",
       " <tf.Tensor: id=552, shape=(), dtype=int64, numpy=3>,\n",
       " <tf.Tensor: id=553, shape=(), dtype=int64, numpy=4>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3]\n",
    "b = tf.data.Dataset.range(4, 5)  # ==> [ 4,]\n",
    "c = a.concatenate(b)\n",
    "list(iter(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=572, shape=(), dtype=int64, numpy=0>,\n",
       " (<tf.Tensor: id=573, shape=(3,), dtype=float32, numpy=array([-0.31130832, -1.3722064 , -0.27330709], dtype=float32)>,\n",
       "  <tf.Tensor: id=574, shape=(), dtype=float32, numpy=99.0>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices((tf.random.normal([4, 3]), [99., 0, 1, 0]))\n",
    "next(iter(a.enumerate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "##### 还有这个不同，啊哈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=582, shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices([ [1, 2, 3], [4, 5, 6], [7, 8, 9] ])\n",
    "next(iter(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=592, shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: id=593, shape=(), dtype=int32, numpy=4>,\n",
       " <tf.Tensor: id=594, shape=(), dtype=int32, numpy=7>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices(( [1, 2, 3], [4, 5, 6], [7, 8, 9] ))\n",
    "next(iter(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = [[1, 2, 3, 4, 5, 6], [1, 2], [1, 2], [1, 2, 3, 4], [1, 2], [1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_generator(lambda: x, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个批次形状不一样，所以错误\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    next(iter(d.batch(2)))\n",
    "except:\n",
    "    print(\"一个批次形状不一样，所以错误\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33129, shape=(2, 6), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4, 5, 6],\n",
       "       [1, 2, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = d.padded_batch(2, [-1])\n",
    "next(iter(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.TensorArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x141f0af98>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.TensorArray(dtype=tf.float32, size=3, infer_shape=False, clear_after_read=False)\n",
    "a = tf.random.normal([3,2,2])\n",
    "x.unstack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=602, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.10629629, -0.19466183],\n",
       "       [-0.4460331 , -0.47419053]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=606, shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[-1.2129303 ,  0.77940047],\n",
       "        [-0.21802388,  0.98266596]],\n",
       "\n",
       "       [[ 1.740146  , -0.34278297],\n",
       "        [-1.3144659 ,  1.0175093 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gather([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=609, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.740146  , -0.34278297],\n",
       "       [-1.3144659 ,  1.0175093 ]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.scatter([2,1,0], a)\n",
    "y.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x141f0a438>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([5,6])\n",
    "x.split(a, [1,2,2]) # 长度分别是1，2，2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=620, shape=(1, 6), dtype=float32, numpy=\n",
       "array([[-3.5588963 , -1.5443984 , -0.6560149 ,  0.4804773 , -0.9900909 ,\n",
       "         0.86643726]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=621, shape=(2, 6), dtype=float32, numpy=\n",
       "array([[-0.48379177,  1.3902569 ,  0.03354906, -0.9551902 ,  1.7645974 ,\n",
       "        -0.33056656],\n",
       "       [ 0.79169416, -0.74314564,  1.0771104 ,  0.33629403, -1.1552415 ,\n",
       "         0.78788143]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "使用`tf.function`一章中的`MyModule`类的实例`m`展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x1422696d8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.save(m, \"data/modelDir\")\n",
    "tf.saved_model.load(\"data/modelDir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "#### tf.train.Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "Checkpoint只保存模型的参数，不保存模型的计算过程，因此一般用于在具有模型源码的时候恢复之前训练好的模型参数。\n",
    "```python3\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.save(save_path_with_prefix)\n",
    "```\n",
    "* 这里tf.train.Checkpoint接受的参数比较特殊，是一个\\*\\*kwargs。具体而言，是一系列键值对，键名可以随便起，值为需要保存的对象。\n",
    "* `save_path_with_prefix`是保存文件的目录+前缀。例如在`checkpoint.save(\"./save/model.ckpt\")`，在save目录下会建立三个文件：`checkpoint, model.ckpt-1.index, model.ckpt-1.data-00000-of-00001`，这些文件记录了变量信息。`checkpoint.save`可以运行多次，每次运行都会得到一个`.index`文件和`.data`文件，序号一次累加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "继续训练模型可以用一下方式实现：\n",
    "```\n",
    "checkpoint = tf.train.Checkpoint(myAwesomeModel=model, myAwesomeOptimizer=optimizer)\n",
    "checkpoint.save(save_path_with_prefix)\n",
    "model_to_be_restored = MyModel() \n",
    "checkpoint = tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)\n",
    "checkpoint.restore(save_path_with_prefix_and_index)\n",
    "```\n",
    "* `save_path_with_prefix_and_index`是之前保存到文件的目录+前缀+编号。例如，调用`checkpoint.restore(\"./save/model.ckpt-1\")`，序号为1的文件来恢复模型。\n",
    "\n",
    "```\n",
    "tf.train.latest_checkpoint(save_path)\n",
    "```\n",
    "* 返回最近一次的checkpoint的文件名，比如返回`./save/model.ckpt-10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ckpt.save.test-1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "如果深度学习模型的权重初始化得太小，那信号将在每层间传递时逐渐缩小而难以产生作用；如果权重初始化的太大，那信号将在每层间传递时逐渐放大并导致发散和失效。  \n",
    "Xavier初始化器让初始化权重满足均值为0，方差为$\\frac{2}{N_{in}+N_{out}}$均匀分布或者高斯分布；\n",
    "\n",
    "* `tf.initializers.glorot_normal()(shape=[20,30])`：创建 $N_{in}=20,N_{out}=30$ 服从正态分布的的初始化权重；\n",
    "* `tf.initializers.glorot_uniform()(shape=[20,30]`：与上面相同，只是服从的是均匀分布。\n",
    "\n",
    "也可以通过下面的api间接实现：  \n",
    "* `tf.random_normal_initializer(mean=0.0,stddev=0.05)(shape=[])`\n",
    "* `tf.random_uniform_initializer(minval=-0.05, maxval=0.05)(shape=[])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tf.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "matrix_band_part(input, num_lower, num_upper)\n",
    "```\n",
    "* num_lower: 下三角要保留的对角线数，-1表示全保留；num_upper类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.529435  ,  0.8286487 ,  1.837228  ,  0.09473267],\n",
       "       [ 0.36858612,  1.0950916 ,  0.62635964,  1.1934665 ],\n",
       "       [-0.7357971 ,  0.18043841, -0.19846489, -0.9738333 ],\n",
       "       [-1.5683837 ,  2.8496115 ,  0.01234788, -0.76184636]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.529435  ,  0.8286487 ,  1.837228  ,  0.09473267],\n",
       "       [ 0.        ,  1.0950916 ,  0.62635964,  1.1934665 ],\n",
       "       [ 0.        ,  0.        , -0.19846489, -0.9738333 ],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.76184636]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(x, 0, -1)  # 变成下三角矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.argmax_v2(input, axis=None, output_type=tf.int64, name=None)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_std # 标准差\n",
    "tf.math.reduce_variance # 方差\n",
    "tf.math.reduce_all\n",
    "tf.math.reduce_any\n",
    "tf.math.reduce_logsumexp # 相当于 tf.math.log(tf.reduce_sum(tf.exp(x)))\n",
    "tf.math.argmin\n",
    "tf.math.argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`tf.matmul(a, b)`  # 将最后两个维度用与矩阵乘法，前面的维度必须完全相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### tf.GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "在tf.GradientTape上下文中执行的所有操作记录下来，用于计算梯度。默认情况下，tf.GradientTape持有的资源会在调用GradientTape.gradient()方法后立即释放。要在同一计算中计算多个梯度，需要创建一个持久梯度带，这允许多次调用gradient()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=770, shape=(), dtype=float32, numpy=108.0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "  t.watch(x)  # 由于x是常数，所以要调用调用watch方法，如果是Variable则不需要这一行\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "dz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
    "dy_dx = t.gradient(y, x)  # 6.0\n",
    "del t  # Drop the reference to the tape\n",
    "dz_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "在上下文中的梯度计算也会被记录下来，因此可以实现高阶梯度计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * x * x\n",
    "    dy_dx = t2.gradient(y,x)\n",
    "d2y_dx2 = t.gradient(dy_dx, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert dy_dx.numpy() == 3.0\n",
    "assert d2y_dx2.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * 8.\n",
    "    y = x * x\n",
    "dydx = tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=824, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dydx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### tf.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
    "```\n",
    "* 其中y_true是系数矩阵，直接的label，而不是one-hot向量\n",
    "* from_logits=False时，y_pred是tf.nn.softmax输出结果，也就是每一个元素都是概率，每一行之和为1\n",
    "* from_logits=True时，y_pred是上一层的输出结果，也就是说softmax(y_pred)运算在此函数内执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "两分类的交叉熵计算，可以看到下面三种计算方式结果一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=849, shape=(), dtype=float32, numpy=0.27290332>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.binary_crossentropy([1,0,1], [0.9,0.3,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876, shape=(), dtype=float32, numpy=0.27290332>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.losses.binary_crossentropy([[1],[0],[1]], [[0.9],[0.3],[0.7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=892, shape=(), dtype=float32, numpy=0.27290347>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.multiply(tf.subtract(1.,[1,0,1.]), tf.math.log(tf.subtract(1.,[0.9,0.3,0.7])))\n",
    "b = tf.multiply([1,0,1.], tf.math.log([0.9,0.3,0.7]))\n",
    "-tf.reduce_mean(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "### tf.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "tf.metrics.categorical_accuracy(y_true, y_pred)\n",
    "* y_true是one-hot向量；y_pred是softmax输出\n",
    "\n",
    "tf.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "* y_true 是系数Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1., 1, 0, 0])\n",
    "b = tf.constant([0.98, 1, 0, 0.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=922, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.BinaryAccuracy(threshold=0.55)(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=934, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.binary_accuracy(a, tf.where(b>0.55, 1., 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=941, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.binary_accuracy(a, b, 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "optimizer.apply_gradient(zip(grads, model.trainable_variables))\n",
    "# .apply_gradient(grads_and_vars)\n",
    "# grads_and_vars: List of (gradient, variable) pairs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "## tf.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "#### tf.nn.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([6,3])\n",
    "b = tf.constant([2,1,1,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: id=950, shape=(6, 2), dtype=float32, numpy=\n",
       "array([[-0.16724938, -0.41634324],\n",
       "       [ 0.053495  , -0.25219882],\n",
       "       [-0.28541866, -0.3039618 ],\n",
       "       [ 0.5407113 , -0.07260029],\n",
       "       [ 0.83685905, -0.5499403 ],\n",
       "       [ 0.864015  ,  0.46615827]], dtype=float32)>, indices=<tf.Tensor: id=951, shape=(6, 2), dtype=int32, numpy=\n",
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [0, 1]], dtype=int32)>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.top_k(a,  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=953, shape=(6,), dtype=bool, numpy=array([False,  True, False,  True,  True,  True])>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.in_top_k(b, a,  2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "#### tf.nn.moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```python\n",
    "tf.nn.moments(x, axes, keep_dims=False)\n",
    "# 若axes=[0,1,2]，则沿着[0,1,2]轴计算mean和variance\n",
    "# keep_dims 返回的结果是否保持原来的维度\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.random.normal([128, 32, 32, 64])\n",
    "m, v = tf.nn.moments(x, [0,1,2], keepdims=True)\n",
    "assert m.shape == [1,1,1,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 相当于\n",
    "m2 = tf.reduce_mean(x, axis=[0,1,2], keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_all(m == m2).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "#### tf.nn.batch_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```pthon\n",
    "tf.nn.batch_normalization(x, mean, variance, offset, scale, variance_epsilion)\n",
    "```\n",
    "* mean, variance可以是`tf.nn.moments`的输出结果\n",
    "* 计算公式：\n",
    "```\n",
    "tmp = (x-mean)/tf.sqrt(variance + variance_epsilon)\n",
    "return tmp * scale + offset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "#### tf.keras.layers.BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```python\n",
    "tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')\n",
    "```\n",
    "* axis：要标准化的特征轴\n",
    "* momentum：移动平均系数\n",
    "* epsilon：同上面的variance_epsilon\n",
    "* scale：是否乘上scale\n",
    "* center：是否加上offset\n",
    "* gamma：同上面scale\n",
    "* beta：同上面offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "设当前层norm的状态为：移动平均值$\\mu$，标准差$\\sigma$；当前mini-batch样本的均值和标准差分别为：$\\mu_i,\\sigma_i$；  系数为$\\alpha$，也就是1 - norm.momentum；则\n",
    "$$\n",
    "\\mu = (1-\\alpha)\\mu + \\alpha \\mu_i \\\\\n",
    "\\sigma = (1-\\alpha)\\sigma + \\alpha\\sigma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "##### [参考这篇文献](https://arxiv.org/pdf/1702.03275.pdf)，其计算过程大概如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([6,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=976, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.8438916 , -1.1968074 ,  0.6201222 ],\n",
       "       [ 0.97026014, -0.5642108 ,  0.08913805],\n",
       "       [-2.0974994 , -0.71609056,  1.570956  ],\n",
       "       [-0.29091766, -2.0045285 ,  0.5246939 ],\n",
       "       [ 2.706988  ,  0.03024667, -0.2271807 ],\n",
       "       [-0.50128317,  2.0827086 , -1.2850046 ]], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=983, shape=(3,), dtype=float32, numpy=array([ 0.2719066 , -0.39478028,  0.21545415], dtype=float32)>,\n",
       " <tf.Tensor: id=984, shape=(3,), dtype=float32, numpy=array([2.2121942, 1.6141806, 0.7600048], dtype=float32)>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.moments(a, axes=0) # 计算均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1049, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.384481  , -0.6310714 ,  0.46387953],\n",
       "       [ 0.4694243 , -0.13331562, -0.14479882],\n",
       "       [-1.5926844 , -0.25282156,  1.5538404 ],\n",
       "       [-0.37832326, -1.2666233 ,  0.35448807],\n",
       "       [ 1.6368306 ,  0.33443055, -0.5074017 ],\n",
       "       [-0.5197283 ,  1.9494009 , -1.7200077 ]], dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = layers.BatchNormalization()\n",
    "norm(a, training=True)  #设置权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "hidden": true
   },
   "source": [
    "##### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/moving_mean:0' shape=(3,) dtype=float32, numpy=array([ 0.00271907, -0.0039478 ,  0.00215454], dtype=float32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.moving_mean # 初始化值为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/moving_variance:0' shape=(3,) dtype=float32, numpy=array([1.0121219, 1.0061418, 0.9976   ], dtype=float32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.moving_variance # 初始化值为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'batch_normalization/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "参数的更新计算方式与下面的计算方式相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1065, shape=(3,), dtype=float32, numpy=array([ 0.00271907, -0.0039478 ,  0.00215454], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum * 0 + tf.nn.moments(a, axes=0)[0] * (1-norm.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1077, shape=(3,), dtype=float32, numpy=array([1.0121219, 1.0061418, 0.9976001], dtype=float32)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.momentum * 1. + tf.nn.moments(a, axes=0)[1] * (1-norm.momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "##### `training=False`时计算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1092, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.83570737, -1.1886226 ,  0.61840063],\n",
       "       [ 0.9612549 , -0.55827296,  0.08704446],\n",
       "       [-2.0865731 , -0.70961326,  1.5699008 ],\n",
       "       [-0.29172894, -1.9934747 ,  0.52290547],\n",
       "       [ 2.6866994 ,  0.03407301, -0.22949594],\n",
       "       [-0.50072765,  2.0792446 , -1.288061  ]], dtype=float32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1104, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.8357074 , -1.1886226 ,  0.6184007 ],\n",
       "       [ 0.9612549 , -0.55827296,  0.08704446],\n",
       "       [-2.0865731 , -0.70961326,  1.5699008 ],\n",
       "       [-0.29172894, -1.9934748 ,  0.5229055 ],\n",
       "       [ 2.6866992 ,  0.03407301, -0.22949594],\n",
       "       [-0.50072765,  2.0792446 , -1.2880611 ]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#等同于下面的计算：\n",
    "(a-norm.moving_mean)/(norm.moving_variance+norm.epsilon)**0.5 * norm.gamma+norm.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "##### `training=True`时的计算方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "我猜测应该是按照下面的方式计算的，不过好像数值有一点差距，暂且不管了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1130, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.384481  , -0.63107145,  0.46387953],\n",
       "       [ 0.4694243 , -0.13331562, -0.14479882],\n",
       "       [-1.5926844 , -0.25282156,  1.5538405 ],\n",
       "       [-0.37832326, -1.2666231 ,  0.35448807],\n",
       "       [ 1.6368306 ,  0.33443055, -0.5074017 ],\n",
       "       [-0.5197283 ,  1.9494011 , -1.7200075 ]], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a-tf.nn.moments(a, axes=0)[0])/(tf.nn.moments(a, axes=0)[1] + norm.epsilon)**0.5 * norm.gamma + norm.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1159, shape=(6, 3), dtype=float32, numpy=\n",
       "array([[ 0.384481  , -0.6310714 ,  0.46387953],\n",
       "       [ 0.4694243 , -0.13331562, -0.14479882],\n",
       "       [-1.5926844 , -0.25282156,  1.5538404 ],\n",
       "       [-0.37832326, -1.2666233 ,  0.35448807],\n",
       "       [ 1.6368306 ,  0.33443055, -0.5074017 ],\n",
       "       [-0.5197283 ,  1.9494009 , -1.7200077 ]], dtype=float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "#### tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1168, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.3310644e-04, 9.9297631e-01, 6.6906218e-03],\n",
       "       [4.5094042e-05, 6.6925492e-03, 9.9326235e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[ 3., 11.,  6.],[ 6., 11., 16.]])\n",
    "tf.nn.softmax(x)\n",
    "# 相当于：tf.exp(x)/tf.expand_dims(tf.reduce_sum(tf.exp(x), axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "#### tf.nn.softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "```\n",
    "* 计算交叉熵，输入是softmax的输入，也就是说softmax的计算是在此函数的内部完成的；\n",
    "* 注意返回是的一个batch的所有样本组成的向量，要求交叉熵，还要使用tf.reduce_sum；\n",
    "* logits:神经网络最后一层的输出，维度是`[batch_size, num_classes]`，如果是单个样本那维度就是num_classes；\n",
    "* labels:样本的实际标签，维度与上面相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1177, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.3310644e-04, 9.9297631e-01, 6.6906218e-03],\n",
       "       [4.5094042e-05, 6.6925492e-03, 9.9326235e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[ 3., 11.,  6.],[ 6., 11., 16.]])\n",
    "tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1181, shape=(2,), dtype=float32, numpy=array([0.0070485 , 0.00676046], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sparse_softmax_cross_entropy_with_logits([1,2], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1220, shape=(2,), dtype=float32, numpy=array([0.0070485 , 0.00676046], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits(tf.one_hot([1,2], depth=3), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1232, shape=(2,), dtype=float32, numpy=array([0.00704847, 0.00676045], dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- tf.reduce_sum(tf.math.log(tf.nn.softmax(x)) * tf.one_hot([1,2], depth=3), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "#### tf.nn.conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "```\n",
    "tf.nn.conv2d(input, filters, strides, padding, data_format='NHWC', dilations=None, name=None)\n",
    "```\n",
    "* 第一个参数input，要求shape必须满足`[batch, in_height, in_weight, in_channels]`，具体的含义是`[训练时一个batch的图片数量，图片高度，图片宽度，图像通道数]`\n",
    "* 第二个参数filters是卷积核，要求shape必须满足`[filter_height,filter_width,in_channels,out_channels]`，具体的含义是`[卷积核的高度，卷积核的宽度，图像的通道数，卷积核的个数]`\n",
    "* \n",
    "* 第三个参数strides，卷积时在图像每一维的步长，这是一个一维张量，对于图片来说，`strides=[1, x, y, 1]，strides[0]==strides[3]==1`；\n",
    "* 第四个参数padding，string类型的量，只能是“SAME”，“VALID”其中之一，这个值决定了不同的卷积方式， padding=\"SAME\"表示有padding，前后补0，保证行列数不变，padding=\"VALID\"表示不加padding；\n",
    "* 第五个参数，use_cudnn_on_gpu: bool类型，是否使用cudnn加速；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 7, 7, 2])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = layers.Conv2D(filters=2, kernel_size=[4,4])\n",
    "x = tf.random.normal([6, 10, 10, 3])\n",
    "t(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 3, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.variables[0].shape # 卷积核权重的个数，每个卷积核大小为[height,width,in_channels]，卷积核的个数为out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.variables[1].shape # 卷积运算的bias个数，每个卷积核对应一个bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "### toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_toy(x, y):\n",
    "    x = tf.cast(x, tf.float32)/255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x,y\n",
    "def toy_dataset(n):\n",
    "    (x,y), _ = keras.datasets.mnist.load_data()\n",
    "    idx = np.random.choice(np.arange(x.shape[0]), n, replace=False)\n",
    "    x,y = x[idx], y[idx]\n",
    "    x = tf.expand_dims(x, 3)\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    train_data = train_data.map(process_toy).repeat()\n",
    "    return train_data.shuffle(64).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## 函数式API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=8, kernel_size=[4,4], activation='relu')(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='KerasFunctionAPIModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=8, kernel_size=[4,4], activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3 steps, validate for 3 steps\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 2.1713 - accuracy: 0.2500 - val_loss: 1.9938 - val_accuracy: 0.3125\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7331 - accuracy: 0.4792 - val_loss: 1.7785 - val_accuracy: 0.4896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b1dc048>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = toy_dataset(100)\n",
    "test_data = toy_dataset(100)\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, epochs=2, steps_per_epoch=3, validation_data=test_data, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "为了把Layer在此一并讲清楚，先定制一个Linear层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, name=\"MyDense\"):\n",
    "        super(MyDense, self).__init__(name=name)\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\"w\", shape=[int(input_shape[-1]), self.units],\n",
    "                                 initializer=tf.initializers.glorot_normal(),\n",
    "                                 trainable=True, regularizer=keras.regularizers.l1(0.001),\n",
    "                                 )\n",
    "        self.b = self.add_weight(\"b\", shape=[self.units, ],\n",
    "                                 initializer=tf.initializers.glorot_uniform(),\n",
    "                                 trainable=True,\n",
    "                                 )\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        y = tf.add(tf.matmul(inputs, self.w) , self.b)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, name=\"MyModel\", **kwargs):\n",
    "        super(MyModel, self).__init__(name=name, **kwargs)\n",
    "        self.conv = layers.Conv2D(filters=8, kernel_size=3, activation='relu', name='conv')\n",
    "        self.flatten = layers.Flatten(name='flatten')\n",
    "        self.mydense = MyDense(64, \"mydense\")\n",
    "        self.dense = layers.Dense(32, activation='relu',\n",
    "                                  use_bias=True,\n",
    "                                  bias_initializer=tf.initializers.glorot_uniform(),\n",
    "                                  kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                                  bias_regularizer=keras.regularizers.l2(0.01),\n",
    "                                  name=\"dense\")\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5, name='dropout')\n",
    "        self.y = layers.Dense(10, 'softmax', name='y')\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        conv = self.conv(inputs)\n",
    "        flatten = self.flatten(conv)\n",
    "        mydense = self.mydense(flatten)\n",
    "        dense = self.dense(mydense)\n",
    "        dropout = self.dropout(dense, training=training)\n",
    "        y = self.y(dropout)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(\"HHH\")\n",
    "train_data = toy_dataset(100)\n",
    "a = next(iter(train_data))[0]\n",
    "model(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 22:17:23.362029 4642928064 save_impl.py:77] Skipping full serialization of Keras model <__main__.MyModel object at 0x141f03cc0>, because its inputs are not defined.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"test/minimodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HHH\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv (Conv2D)                multiple                  80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "mydense (MyDense)            multiple                  346176    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "y (Dense)                    multiple                  330       \n",
      "=================================================================\n",
      "Total params: 348,666\n",
      "Trainable params: 348,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=2761, shape=(), dtype=float32, numpy=5.4401956>,\n",
       " <tf.Tensor: id=2769, shape=(), dtype=float32, numpy=0.4249903>,\n",
       " <tf.Tensor: id=2777, shape=(), dtype=float32, numpy=0.010632831>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=2785, shape=(), dtype=float32, numpy=5.4401956>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('mydense').losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5408, 64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('mydense').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "tf.keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None)\n",
    "```\n",
    "* units: 输出神经元个数\n",
    "* activation：激活函数\n",
    "* use_bias: Boolean, whether the layer uses a bias vector\n",
    "* kernel_initializer: Initializer for the `kernel` weights matrix.\n",
    "* bias_initializer: Initializer for the bias vector.\n",
    "* kernel_regularizer: Regularizer function applied to the `kernel` weights matrix.\n",
    "* bias_regularizer: Regularizer function applied to the bias vector.\n",
    "* `Dense` implements the operation: `output = activation(dot(input, kernel) + bias)`；因此如果是输入没有经过Flatten，也就是多个维度，那么输出本层相当于进行了一次$1\\times1$的卷积；\n",
    "* input一行是一个样本，那么kernel的行数就是输入神经元的个数，kernel的列数就是输出神经元的个数。\n",
    "* Input shape: (batch_size, input_dim)\n",
    "* Output shape: (batch_size, units)\n",
    "* `__call__(self, inputs, *args, **kwargs)`方法：会调用`call`方法，返回输出张量\n",
    "* 如果本层在第一层，可以通过参数`input_dim=512`指定输入的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',input_length=None)\n",
    "```\n",
    "* `input_dim`是单词表的长度+1，`output_dim`是嵌入向量的长度，`input_length`：仅截取每个样本的前`input_length`个词\n",
    "* 输入是一个batch的数据，其中每个样本的每个单词是其在单词表中的下标；输出增加了一个维度，就是单词用嵌入向量表示了\n",
    "* `.get_weights()`返回该层的参数，`shape=[input_dim, output_dim]`，每一行代表了一个单词的嵌入向量（跳字模型的中心词向量）\n",
    "* input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect `Flatten`, then `Dense` layers upstream (without it, the shape of the dense outputs cannot be computed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 10, 3])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = layers.Embedding(10, 3, input_length=8)\n",
    "x = np.random.randint(8, size=[20, 10])\n",
    "embed(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### layers.SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "layers.SimpleRNN(units, return_sequences)\n",
    "```\n",
    "* 零时间步的初始状态为全0向量，之后的每一步输出是下一个时间步的状态；\n",
    "* rnn的每一个时间步的输入shape是`[batch_size,timesteps, input_features]`\n",
    "* 输出的shape是`[batch_size, output_features]`，`output_features`就是参数中的units\n",
    "* 如果参数设置为`return_sequences=True`，则输出的shape为`[batch_size, timesteps, output_features]`，也就是每个时间步都输出，如果作为中间层，则应该设置为`return_sequences=True`\n",
    "* `self.build(input_shape=[])`，初始化权重，第一个权重的第一个维度是`input_shape[-1]`，第二个维度是输出的维度units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 8, 5])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = layers.SimpleRNN(5, return_sequences=True)\n",
    "x = tf.random.normal([6, 8, 3])\n",
    "rnn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "(5, 5)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "for i in rnn.trainable_variables:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3142, shape=(5,), dtype=float32, numpy=\n",
       "array([-0.8712967 , -0.09798537, -0.9270312 , -0.39548007,  0.7941837 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是第一个样本，第二个时间步的计算过程，数值稍微有点出入，且不深究\n",
    "a = np.dot(x[0,1], rnn.get_weights()[0])\n",
    "b = np.dot(rnn(x)[0,0], rnn.get_weights()[1])\n",
    "r = tf.nn.tanh(a+b+rnn.get_weights()[2])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3282, shape=(5,), dtype=float32, numpy=\n",
       "array([-0.8712967 , -0.09798539, -0.9270312 , -0.39548007,  0.7941837 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(x)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### layers.LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors:\n",
    "- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\n",
    "- If using the functional API, specify the batch size by passing a `batch_shape` argument to your Input layer.\n",
    "- 下面的测试说明，如果是用subclass则不需要任何改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestStateful(keras.Model):\n",
    "    def __init__(self, name='TestStateful', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.embed = layers.Embedding(10, 3)\n",
    "        self.lstm = layers.LSTM(4, return_sequences=True, stateful=True)\n",
    "    def call(self, inputs, training=False):\n",
    "        embed = self.embed(inputs)\n",
    "        lstm = self.lstm(embed)\n",
    "        return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 10, 4])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TestStateful()\n",
    "x = np.random.randint(8, size=[20, 10])\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.lstm.states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到有两个状态，应该一个是最后一个输出，另一个是“传送带”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = layers.LSTM(10, return_state=True, return_sequences=True)\n",
    "x = tf.random.normal([6, 8, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 10])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x)[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "双向RNN利用的RNN的顺序敏感性：它包含两个普通RNN，每个RNN分别沿一个方向对输入序列进行处理（时间正序和时间逆序），然后将它们的表示合并到一起（concat）。通过沿这两个方向处理序列，双向RNN能捕捉到可能被单向RNN忽略的模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "layers.Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None)\n",
    "```\n",
    "* 一维卷积神经网络用于文本和序列\n",
    "* 输入的形状是(batch_size, timesteps, features)，在时间轴上做卷积；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.MaxPooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "layers.MaxPooling(pool_size=2, strides=None, padding='valid', data_format='channels_last')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "layers.GlobalAveragePooling1D(data_format='channels_last')\n",
    "```\n",
    "* 默认输入为`[batch,timesteps,features]`，在`timesteps`维度上做池化；形象点就是在这一批次的词中，在每一个词向量的同一维度上做池化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### layers.Conv2DTranspose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "原理参考[这篇文献](https://arxiv.org/pdf/1603.07285.pdf)，在第20页，4.1节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ', split=' ')\n",
    "```\n",
    "* `num_words`：只有最常出现的`num_words`个词会被保留\n",
    "* `filters`：会被过滤掉的，实际上可以认为被替换成`split`指定的分割字符串\n",
    "* `split`：指定分割文本用的字符串，默认是空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = prep.text.Tokenizer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"if you want to sound like a native speaker , you must be willing to practice saying the want to to sound native\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([x, ])  # 参数字符串组成的list，得到按词频排序的单词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(['you you you you you']) # 接着训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'you',\n",
       " 2: 'to',\n",
       " 3: 'want',\n",
       " 4: 'sound',\n",
       " 5: 'native',\n",
       " 6: 'if',\n",
       " 7: 'like',\n",
       " 8: 'a',\n",
       " 9: 'speaker',\n",
       " 10: 'must',\n",
       " 11: 'be',\n",
       " 12: 'willing',\n",
       " 13: 'practice',\n",
       " 14: 'saying',\n",
       " 15: 'the'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word  # 下标-单词 组成的字典，包括所有单词，词频大的下标小；.word_index与之相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenizer.word_counts # [(单词，频率), (...), ...]，是一个OrderedDict，按训练样本中单词出现的顺序排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 2], [2, 3, 1]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"you are want to a\", \"a to want are you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you want to']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[1,3,2, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_matrix(['you are wang to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'are', 'my', 'best', 'friend', 'you']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.text.text_to_word_sequence('you are my best friend you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.preprocessing.sequence.TimeseriesGenerator(data, targets, length, sampling_rate=1, stride=1, start_index=0, end_index=None, shuffle=False, reverse=False, batch_size=128)\n",
    "```\n",
    "* `data`：是可索引的生成器（例如元组，列表或numpy数组），第0个轴是时间维度\n",
    "* `targets`：对应的data时间步的目标值，第0个维度与data的时间维度长度相同\n",
    "* `length`：每个样本有考虑多少个时间步，或者说当sampling_rate=1时，生成的结果中一个targets值对应多少个data值\n",
    "* `sampling_rate`：时间步的采样周期，例如当`length=10, sampleing_rate=2`时，每2个时间步取一次，结果就是每个目标值只对应5个时间步，但是跨越了10个时间步\n",
    "* `stride`：目标值的采样周期\n",
    "* `start_index,end_index`：data和targets的下标在`[start_index, end_index]`之间的时间步才会被用到\n",
    "* `shuffle`：是否打乱样本\n",
    "* `reverse`：是否按时间步的倒序输出\n",
    "* `batch_size`：每个批次的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([chr(i) for i in range(97, 117)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[i] for i in range(50)])\n",
    "targets = np.random.normal(size=[50, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = prep.sequence.TimeseriesGenerator(data, targets, length=10, sampling_rate=2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.],\n",
       "         [2.],\n",
       "         [4.],\n",
       "         [6.],\n",
       "         [8.]],\n",
       " \n",
       "        [[1.],\n",
       "         [3.],\n",
       "         [5.],\n",
       "         [7.],\n",
       "         [9.]]]), array([[-0.9120223 , -0.44903765, -0.45272137],\n",
       "        [-1.5934117 ,  0.01738436,  0.91008626]]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9120223 , -0.44903765, -0.45272137])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "prep.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
    "```\n",
    "* sequences：列表的列表，每一个元素是一个序列\n",
    "* maxlen：默认是所有序列中最长的长度\n",
    "* value：浮点数，用来补齐的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [0, 3],\n",
       "       [4, 5]], dtype=int32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,3], [3,], [4,5]]\n",
    "prep.sequence.pad_sequences(x, maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32801, shape=(1, 20), dtype=int64, numpy=array([[0, 0, 0, 0, 2, 1, 0, 2, 2, 3, 3, 0, 1, 4, 2, 2, 3, 3, 3, 0]])>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.categorical([tf.nn.softmax(tf.random.normal([5]))], 20)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tfds.features.text.Tokenizer(alphanum_only=True, reserved_tokens=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"one one two two th,ree one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th,ree', 'one']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer(reserved_tokens=['th,ree',])\n",
    "tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', ' ', 'one', ' ', 'two', ' ', 'two', ' ', 'th', ',', 'ree', ' ', 'one']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer(alphanum_only=False)\n",
    "tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th', 'ree', 'one']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tfds.features.text.TokenTextEncoder(tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'one', 'two', 'two', 'th', 'ree', 'one']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.SubwordTextEncoder.build_from_corpus(['one two aa aaa ', 'you are one two aa aa bbb,bb'], target_vocab_size=2**15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa_', 'two_', 'one_', 'you_', 'bbb', 'bb', 'are_', 'aaa_']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 1, 93, 41, 125]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode('aa aaa aa T t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 106, 106, 106, 41, 46, 46, 41, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode('aaa aaa %% two ') # 为啥第二个aaa_被分割成字母了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one aa one #'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder.decode([3, 1, 0, 3]) # ValueError，0只能在最后\n",
    "encoder.decode([3, 1, 3, 44, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 41, 5, 6]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode('bb bbbbb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "203px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
