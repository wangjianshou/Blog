{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "##### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amsterdam', 'paris', 'tokyo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = prep.LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = prep.LabelBinarizer()\n",
    "# 与OneHotEncoder的区别是LabelBinarizer只对一维数据编码，主要用于target编码，而不是特征\n",
    "# Binarize labels in a one-vs-all fashion\n",
    "t = binarizer.fit(iris.target).transform(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,12).reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,3],[0,5],[10,6]])\n",
    "b = prep.OneHotEncoder(categories='auto').fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  1, 10]), array([3, 5, 6])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.transform(a).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([['c'], ['b'], ['a']])\n",
    "scaler = prep.OneHotEncoder(categories=[['a','b','c','f']]).fit(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "simputer = impute.SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simputer.fit([[1, 2], [np.nan, 3], [7, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.        , 3.66666667])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "参数stragegy：mean，median，most_frequent，constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# 建立其他特征预测某一特征的回归模型，预测缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = binarizer.fit(iris.target).transform(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "scores = np.array([0.2, 0.6, 0.4, 0.6, 0.8, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threads = metrics.roc_curve(y, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.33333333, 1.        ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.66666667, 1.        , 1.        ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8, 0.8, 0.6, 0.2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.auc(fpr, tpr)  # 计算曲线下面的面积，fpr必须是单调递增或递减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x12d6c6de0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(3, shuffle=False) # shuffle=False时，按照原先的排序分\n",
    "k_fold.split(iris.data)  # 得到生成器，每次返回(test_indices, train_indices)，训练集和测试集的下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseShuffleSplit.split at 0x12d6c6ed0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl = model_selection.ShuffleSplit(n_splits=3,test_size=None, train_size=None)  # n_splits=3表示分3次\n",
    "spl.split(iris.data, iris.target)  # 返回生成器，迭代3次，每次都是按照test_size,train_size比例划分的X和Y数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=None,\n",
       "            train_size=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.StratifiedShuffleSplit(n_splits=10) # 按照Y类别分层split数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "      iris.data, iris.target, test_size=0.33, random_state=42)\n",
    "# 实际上就是包装了ShuffleSplit，直接返回划分后的数据，而不是下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(c, data, target, cv=kv, scoring=scorer)\n",
    "# cross_val_score(c, data, target, cv=kv)\n",
    "# 交叉验证，返回每次验证集上的score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 看一下有没有过拟合的嫌疑\n",
    "train_size, train_accuracy, test_accuracy = learning_curve(c, data, target, cv=kv, shuffle=True, random_state=999, train_sizes = [0.1,0.25,0.5,0.75,0.9,1])\n",
    "plt.plot(train_size, train_accuracy.mean(axis=1), 'o-', color='r', label='Training')\n",
    "plt.plot(train_size, test_accuracy.mean(axis=1), 'o-', color='g', label='Test')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import learning_curve,validation_curve,cross_val_score,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = metrics.make_scorer(metrics.roc_auc_score, needs_threshold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpo = model_selection.LeavePOut(1)\n",
    "kv = model_selection.StratifiedKFold(3, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10,20,30,50,100,120,150]\n",
    "max_depth = [2,3,4,5,6]\n",
    "min_impurity_decrease = [0,0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "max_features = [5,10,15,20, 25] # 最后调\n",
    "criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xgb.DMatrix(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作者：章华燕\n",
    "链接：https://zhuanlan.zhihu.com/p/31182879\n",
    "```\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类的问题\n",
    "    'num_class': 10,               # 类别数，与 multisoftmax 并用\n",
    "    'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample': 0.7,              # 随机采样训练样本\n",
    "    'colsample_bytree': 0.7,       # 生成树时进行的列采样\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.007,                  # 如同学习率\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,                  # cpu 线程数\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<head>\n",
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js\"></script>\n",
       "<head>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641094095"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(boston.data, boston.target)\n",
    "reg._residues  # 残差平方和\n",
    "reg.score(boston.data, boston.target)  # R square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.Ridge(alpha=0.5)\n",
    "reg.fit(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739957023371629"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([0.01, 0.02, 0.05, 0.1 , 0.5 ]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.RidgeCV(alphas=[0.01,0.02,0.05,0.1,0.5])\n",
    "reg.fit(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406313966518082"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = naive_bayes.GaussianNB().fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.121764, 0.140816, 0.029556, 0.010884],\n",
       "       [0.261104, 0.0965  , 0.2164  , 0.038324],\n",
       "       [0.396256, 0.101924, 0.298496, 0.073924]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.sigma_ # 方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.006, 3.428, 1.462, 0.246],\n",
       "       [5.936, 2.77 , 4.26 , 1.326],\n",
       "       [6.588, 2.974, 5.552, 2.026]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.theta_ # 均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.006, 3.428, 1.462, 0.246])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[iris.target==0,].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "minsplit = [2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc = validation_curve(c, breast.data, breast.target, param_name='max_depth', param_range=depth, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 10)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92098997, 0.90689223, 0.91929825, 0.9174812 , 0.92098997,\n",
       "       0.92277569, 0.92271303, 0.92277569, 0.9139411 , 0.91218672,\n",
       "       0.91920426, 0.92277569, 0.910401  , 0.90698622, 0.92446742])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "c = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(c, dict(max_depth=depth, min_samples_split=minsplit), cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                       14, 15, 16],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8]})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred, labels=None, pos_label=1, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = prep.StandardScaler()\n",
    "digits = datasets.load_digits()\n",
    "clf = svm.SVC(kernel='rbf', C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = digits.data\n",
    "x = scaler.fit(x).transform(x)\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, train_loss, test_loss = learning_curve(\n",
    "    clf, x, y, cv=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    train_sizes=[0.1,0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_mean = -np.mean(train_loss,axis=1)\n",
    "test_loss_mean = -np.mean(test_loss,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.267455  , 1.49271881, 0.7245779 , 0.62676909, 0.33842644])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -0., -0., -0., -0.])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 161,  404,  808, 1212, 1617])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_size,train_loss_mean,'o-',color='r',label='Training')\n",
    "plt.plot(train_size,test_loss_mean,'o-',color='g',label='Cross-validation')\n",
    "plt.legend('best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`sklearn.svm.LinearSVC` or\n",
      " |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int or RandomState instance, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : ndarray of shape (n_SV,)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_class,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_class-1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_class * (n_class-1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_class * (n_class-1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_class * (n_class-1) / 2)\n",
      " |  probB_ : ndarray of shape (n_class * (n_class-1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  class_weight_ : ndarray of shape (n_class,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  probA_\n",
      " |  \n",
      " |  probB_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
